{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1774a07d",
   "metadata": {},
   "source": [
    "# Benchmark and compare Whisper models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53315d",
   "metadata": {},
   "source": [
    "In this notebook, we try to apply transcription and classification with \n",
    "\n",
    "Whisper (Large vs Turbo, CPP AND GPU versions) and Analyse the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b50ca",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74716fe",
   "metadata": {},
   "source": [
    "We start with generating transcription with both models(turbo and large-v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf586a2",
   "metadata": {},
   "source": [
    "Let's choose a sample of random audios(100 units), so we make sure our sample is representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a938d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# audio_folder = '../../metadata/chunks/audio' \n",
    "# transcriptions_file = '../../metadata/chunks/text_audio_mapping.json'\n",
    "# saving_file = '../json/selected_audio_files.json'\n",
    "# AUDIO_NUM = 100\n",
    "\n",
    "# audio_files = os.listdir(audio_folder)\n",
    "# random.shuffle(audio_files)\n",
    "\n",
    "# selected_audio_files = audio_files[:AUDIO_NUM]\n",
    "\n",
    "# # add original transcriptions\n",
    "# data = None\n",
    "# with open(transcriptions_file, 'r') as f:\n",
    "#     transcriptions = json.load(f)\n",
    "\n",
    "# json_objects = []\n",
    "\n",
    "# for file in selected_audio_files:\n",
    "#     audio_name = file.replace(\".mp3\", \"\")\n",
    "#     transcription = next(t['text'] for t in transcriptions if t['audio'] == audio_name )\n",
    "#     json_objects.append(\n",
    "#         {\n",
    "#             \"audio\": audio_name,\n",
    "#             \"transcription\": transcription\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# with open(saving_file, 'w') as f:\n",
    "#     json.dump(json_objects, f, ensure_ascii=False)\n",
    "\n",
    "# print(selected_audio_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c0f2",
   "metadata": {},
   "source": [
    "We will transcribe these audio files using Whisper Large-v3 and Turbo and see the quality and time\n",
    "\n",
    "This will run in colab Tesla T4 (12.7 GB VRAM as the runtime shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86096e5b",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae61c18",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats (first run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec241",
   "metadata": {},
   "source": [
    "\n",
    "📊 Summary:\n",
    "\n",
    "Mean time: 27.55 s\n",
    "Min time : 7.81 s\n",
    "Max time : 101.91 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058386f5",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats(second run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddce50",
   "metadata": {},
   "source": [
    "📊 Summary:\n",
    "Mean time: 26.32 s\n",
    "Min time : 9.90 s\n",
    "Max time : 64.60 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d388c5",
   "metadata": {},
   "source": [
    "## Whisper Turbo stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e8132",
   "metadata": {},
   "source": [
    "\n",
    "📊 Summary:\n",
    "Mean time: 8.86 s\n",
    "Min time : 3.21 s\n",
    "Max time : 21.19 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5e82f",
   "metadata": {},
   "source": [
    "### <span style='color:blue'> *Turbo is more that x3 times faster than Large* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94e50e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01f578",
   "metadata": {},
   "source": [
    "The transcriptions are saved in **json/test_whisper_(model).json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac2951",
   "metadata": {},
   "source": [
    "## Manual Evaluation\n",
    "We evaluate the quality of transcriptions manually\n",
    "- 013_chunk056: Turbo much better\n",
    "- 017_chunk152: Large is horrible, Turbo is good\n",
    "- 013_chunk035: Kinda the same quality, both good\n",
    "- 008_chunk022: Large misses a portion of speech, Turbo is worse\n",
    "- 020_chunk039: Turbo is good, Large is same\n",
    "- 016_chunk010: Large is better\n",
    "- 022_chunk015: both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceec0b9",
   "metadata": {},
   "source": [
    "## Numerical Evaluation(cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aecb1f",
   "metadata": {},
   "source": [
    "we load the both transcription data, with youtube(original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a1a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whisper_turbo.json'\n",
    "whisper_large_t = '../json/test_whisper_large-v3.json'\n",
    "original_t = '../json/text_audio_mapping.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n",
    "\n",
    "with open(original_t, 'r') as f:\n",
    "    original_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068788e",
   "metadata": {},
   "source": [
    "Filter originals list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43aebb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick test: length of filtered list: 100\n"
     ]
    }
   ],
   "source": [
    "# load chosen audio list\n",
    "chosen_audio_f = '../json/selected_audio_files.json'\n",
    "original_filtered = []\n",
    "\n",
    "with open(chosen_audio_f, 'r') as f:\n",
    "    chosen_audio_list = json.load(f)\n",
    "for row in original_transcriptions:\n",
    "    found = next((1 for f in chosen_audio_list if f['audio'] == row['audio']), None)\n",
    "    if found:\n",
    "        original_filtered.append(row)\n",
    "\n",
    "print(f\"quick test: length of filtered list: {len(original_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb72cdf",
   "metadata": {},
   "source": [
    "### Generate embeddings for whisper transcriptions and save them in new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b29c5",
   "metadata": {},
   "source": [
    "Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b360f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "your_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8493ee5",
   "metadata": {},
   "source": [
    "Generating embedding using OpenAI multilingual transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff3f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# we use 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def add_embeddings(data_list, text_key):\n",
    "    \"\"\"\n",
    "    Generates and adds embeddings for each item in a list of dictionaries.\n",
    "\n",
    "    Args: \n",
    "        data_list (list): A list of dictionaries, where each dict has a text field.\n",
    "        text_key (str): The key for the text field in each dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list with an '_embedding' key added to each dictionary.\n",
    "    \"\"\"\n",
    "    texts = [item.get(text_key) for item in data_list]\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "\n",
    "    for i, item in enumerate(data_list):\n",
    "        new_key = text_key + '_embedding'\n",
    "        item[new_key] = embeddings[i].tolist() # Convert numpy array to list for JSON serialization\n",
    "\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d1e97",
   "metadata": {},
   "source": [
    "save in a different file for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa74dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turbo_embeddings_path = '../json/turbo_embeddings.json'\n",
    "large_embeddings_path = '../json/large_embeddings.json'\n",
    "origial_embeddings_path = '../json/origial_embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_embeddings = add_embeddings(turbo_transcriptions, \"transcription\")\n",
    "large_embeddings = add_embeddings(large_transcriptions, \"transcription\")\n",
    "original_embeddings = add_embeddings(original_filtered, \"text\")\n",
    "\n",
    "\n",
    "with open(turbo_embeddings_path, 'w') as f:\n",
    "    json.dump(turbo_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(large_embeddings_path, 'w') as f:\n",
    "    json.dump(large_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(origial_embeddings_path, 'w') as f:\n",
    "    json.dump(original_embeddings, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c44639",
   "metadata": {},
   "source": [
    "## Apply cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9356a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(turbo_embeddings_path, 'r') as f:\n",
    "    turbo_embeddings = json.load(f)\n",
    "\n",
    "with open(large_embeddings_path, 'r') as f:\n",
    "    large_embeddings = json.load(f)\n",
    "\n",
    "with open(origial_embeddings_path, 'r') as f:\n",
    "    original_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196033d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_file = '../json/turbo_vs_large.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51a5dd",
   "metadata": {},
   "source": [
    "Apply cosine similarity and save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0767f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for row in original_embeddings:\n",
    "    original_emb = row['text_embedding']\n",
    "    turbo_emb = next((f['transcription_embedding'] for f in turbo_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "    large_emb = next((f['transcription_embedding'] for f in large_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "\n",
    "    if not turbo_emb:\n",
    "        print(f\"NOT FOUND turbo embedding for file {row['audio']}\")\n",
    "\n",
    "    if not large_emb:\n",
    "        print(f\"NOT FOUND large embedding for file {row['audio']}\")\n",
    "    original_emb = np.array(original_emb).reshape(1, -1)\n",
    "    turbo_emb = np.array(turbo_emb).reshape(1, -1)\n",
    "    large_emb = np.array(large_emb).reshape(1, -1)\n",
    "\n",
    "    turbo_cosine = cosine_similarity(original_emb, turbo_emb)[0][0]\n",
    "    large_cosine = cosine_similarity(original_emb, large_emb)[0][0]\n",
    "\n",
    "    metric_list.append({\n",
    "        \"audio\": row['audio'],\n",
    "        'turbo_cosine': turbo_cosine,\n",
    "        'large_cosine': large_cosine\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metric_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6b40c",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bdcd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>turbo_cosine</th>\n",
       "      <th>large_cosine</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_chunk007</td>\n",
       "      <td>0.957282</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>-0.028034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_chunk018</td>\n",
       "      <td>0.953961</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>-0.020346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_chunk019</td>\n",
       "      <td>0.894270</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.049578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_chunk005</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.940228</td>\n",
       "      <td>0.036657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_chunk002</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.950694</td>\n",
       "      <td>-0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>022_chunk009</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.833761</td>\n",
       "      <td>-0.154815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>022_chunk015</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.876124</td>\n",
       "      <td>-0.089463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>022_chunk027</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>0.012392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>022_chunk035</td>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.886476</td>\n",
       "      <td>-0.020563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>022_chunk055</td>\n",
       "      <td>0.842067</td>\n",
       "      <td>0.937556</td>\n",
       "      <td>0.095489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio  turbo_cosine  large_cosine  difference\n",
       "0   002_chunk007      0.957282      0.929248   -0.028034\n",
       "1   002_chunk018      0.953961      0.933615   -0.020346\n",
       "2   002_chunk019      0.894270      0.943848    0.049578\n",
       "3   004_chunk005      0.903571      0.940228    0.036657\n",
       "4   005_chunk002      0.972451      0.950694   -0.021757\n",
       "..           ...           ...           ...         ...\n",
       "95  022_chunk009      0.988576      0.833761   -0.154815\n",
       "96  022_chunk015      0.965587      0.876124   -0.089463\n",
       "97  022_chunk027      0.908584      0.920975    0.012392\n",
       "98  022_chunk035      0.907040      0.886476   -0.020563\n",
       "99  022_chunk055      0.842067      0.937556    0.095489\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Comparison ---\n",
      "turbo_mean: 0.9261\n",
      "large_mean: 0.9148\n",
      "turbo_std: 0.0809\n",
      "large_std: 0.0644\n",
      "avg_difference: -0.0113\n",
      "turbo_better_count: 66.0000\n",
      "large_better_count: 34.0000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metric_list = json.load(f)\n",
    "\n",
    "# put into DataFrame\n",
    "df = pd.DataFrame(metric_list)\n",
    "\n",
    "# compute difference\n",
    "df[\"difference\"] = df[\"large_cosine\"] - df[\"turbo_cosine\"]\n",
    "\n",
    "# summary statistics\n",
    "summary = {\n",
    "    \"turbo_mean\": df[\"turbo_cosine\"].mean(),\n",
    "    \"large_mean\": df[\"large_cosine\"].mean(),\n",
    "    \"turbo_std\": df[\"turbo_cosine\"].std(),\n",
    "    \"large_std\": df[\"large_cosine\"].std(),\n",
    "    \"avg_difference\": df[\"difference\"].mean(),\n",
    "    \"turbo_better_count\": (df[\"difference\"] < 0).sum(),\n",
    "    \"large_better_count\": (df[\"difference\"] > 0).sum()\n",
    "}\n",
    "\n",
    "display(df)\n",
    "print(\"\\n--- Summary Comparison ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddd808",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Turbo model looks much better for this test unit </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a540c3",
   "metadata": {},
   "source": [
    "# **CPU Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7563e97",
   "metadata": {},
   "source": [
    "function to transcribe audio using the cpp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d39a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def transcribe_audio(\n",
    "    audio_path,\n",
    "    text_output_dir,\n",
    "    exe_path,\n",
    "    model_name=\"large-v3\",\n",
    "    language=\"ar\",\n",
    "    threads=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Whisper.cpp on a given audio file and store the .txt output\n",
    "    in a separate folder (text_output_dir).\n",
    "    Returns the transcribed text.\n",
    "    \"\"\"\n",
    "    model_path = r\"C:\\Users\\ACER\\whisper.cpp\\models\\ggml-\" + model_name + \".bin\" \n",
    "    audio_path = Path(audio_path)\n",
    "    text_output_dir = Path(text_output_dir)\n",
    "    text_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Use the audio file name but save inside text_output_dir\n",
    "    # Corrected path handling\n",
    "    txt_output = text_output_dir / audio_path.stem  # no extension here\n",
    "\n",
    "    cmd = [\n",
    "        exe_path,\n",
    "        \"-m\", model_path,\n",
    "        \"-f\", str(audio_path),\n",
    "        \"-l\", language,\n",
    "        \"-t\", str(threads),\n",
    "        \"-otxt\",\n",
    "        \"-of\", str(txt_output)  # whisper.cpp will add .txt automatically\n",
    "    ]\n",
    "\n",
    "    final_txt_file = txt_output.with_suffix(\".txt\")\n",
    "\n",
    "    subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if final_txt_file.exists():\n",
    "        return final_txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda044a",
   "metadata": {},
   "source": [
    "get the sample of audio files that we already chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fc4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'audio': '013_chunk056', 'transcription': 'جو سوي سور كاينين حتى فيلالجيريا كاين في العالم كامل واحد الناس كيتزادوا تيحس براسه ان ملي كنت كنشعل التلفازه ما كانتش كتعني لي شي حاجه هذوك راه الناس الها اه احنا الناس اللي لهيه فهمتي هذو راه كاينين كاينين في العاصمه حنا شعبون ثاني اه اه فهمتي ماتيعنيونيش الطريقه باش كيلبسوا لابس كوستيوم ختنا لابسه فيست كذا لا علاقه ما عندكش لابارتونونس لهذك لا علاقه انا تنعرف الكارتي ديالنا 200 دولار اخاي بهذا الشي اللي شنو يقدر يدير ب 200 دولار الهضره ديال الصاك كامله صحيحه غير انايا دي نزل للتيران ورا ما محتاجش ل 200 دولار كاين يقدر ما نحتاجش ما قال ما نحتاج حتاجش كاع 200 دولار انا ح انا نقدر نزل للسوق ندير الترجمه نحل فايفر شوف شنو اللي مشي واش نقدر ندير هذا ليماج ايديتينغ اللي طالبين غنمشي نزحم هذا حى انا ندير معه المنافسه هو كيطلب 50 دولار فايفر انا اخويا ندير غير ب 5 دولار انا مسالي ما عندي ما ندير 5 دولار في المغرب والجزائر راه شي حاجه ا 120 ولا صافا را'}, {'audio': '017_chunk152', 'transcription': 'الكونت بيبليسيتير هذاك قد ما تستقوى قد ما هو يسيبلي على حساب واش عنده دطا وكاين طرق باش نالونتي الداطا كي نكونوا جدد اللي حكينا عليهم لايفك هنا بلوس بلوس فليكسيبل كي تخدم لهم في الافتتاح البارح على هذا عطيت لهم حصريه راني باركت لكارمون نورمالمون ماطلعتش في البودكاست هذا نباركو خونا روجي وسي نزيم نحيوه بالمناسبه تجربه جديده ار جي 360 ربي يوفق ان شاء الله ويكون مجتمع رقمي عنده امباكت كبير في الاقتصاد الله نشوفهم في المستقبل على خمس سنوات يحطوا حاجه في سبحان الله حتى نخطط على خمس سنوات الله يبارك ما شاء الله دونك ا كي قلنا الفليكسيبل لادفونطج بليس را يدوموندينا ما نخدموش غير كونفرجيت ويب بصح احنا لازمنا نخدموا كونفرجي ويب دونك اللعبه اللي راي كاينه درك كاينه لي ميت نمتها انك تكري حمله الاعلانيه ادفونتاج'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# load chosen audio list\n",
    "chosen_audio_f = '../json/selected_audio_files.json'\n",
    "original_filtered = []\n",
    "\n",
    "with open(chosen_audio_f, 'r') as f:\n",
    "    chosen_audio_list = json.load(f)\n",
    "\n",
    "print(chosen_audio_list[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293caaf",
   "metadata": {},
   "source": [
    "We start with the Large-v3 cpu model. we use 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b59741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_dir = '../json'\n",
    "\n",
    "os.makedirs(saving_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2016c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔊 Transcribing: 013_chunk056.mp3\n",
      "⏱  Took 106.71 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk152.mp3\n",
      "⏱  Took 112.47 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk035.mp3\n",
      "⏱  Took 105.54 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk053.mp3\n",
      "⏱  Took 126.92 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk022.mp3\n",
      "⏱  Took 155.55 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk141.mp3\n",
      "⏱  Took 134.97 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk039.mp3\n",
      "⏱  Took 121.89 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk020.mp3\n",
      "⏱  Took 131.88 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk010.mp3\n",
      "⏱  Took 119.32 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk107.mp3\n",
      "⏱  Took 146.40 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk018.mp3\n",
      "⏱  Took 173.38 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk015.mp3\n",
      "⏱  Took 182.32 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk045.mp3\n",
      "⏱  Took 109.45 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk058.mp3\n",
      "⏱  Took 119.22 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk085.mp3\n",
      "⏱  Took 342.53 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk013.mp3\n",
      "⏱  Took 104.86 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk029.mp3\n",
      "⏱  Took 125.01 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk021.mp3\n",
      "⏱  Took 122.01 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk086.mp3\n",
      "⏱  Took 106.47 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk041.mp3\n",
      "⏱  Took 127.13 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk049.mp3\n",
      "⏱  Took 113.08 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk005.mp3\n",
      "⏱  Took 159.75 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk015.mp3\n",
      "⏱  Took 130.06 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk043.mp3\n",
      "⏱  Took 111.51 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk154.mp3\n",
      "⏱  Took 153.36 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk083.mp3\n",
      "⏱  Took 126.90 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk158.mp3\n",
      "⏱  Took 153.66 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk056.mp3\n",
      "⏱  Took 123.45 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk033.mp3\n",
      "⏱  Took 109.38 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk122.mp3\n",
      "⏱  Took 126.86 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk015.mp3\n",
      "⏱  Took 170.33 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk050.mp3\n",
      "⏱  Took 123.90 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk019.mp3\n",
      "⏱  Took 124.35 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk134.mp3\n",
      "⏱  Took 140.06 seconds\n",
      "\n",
      "🔊 Transcribing: 004_chunk005.mp3\n",
      "⏱  Took 102.49 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk007.mp3\n",
      "⏱  Took 120.14 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk009.mp3\n",
      "⏱  Took 108.58 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk112.mp3\n",
      "⏱  Took 106.48 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk003.mp3\n",
      "⏱  Took 112.94 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk055.mp3\n",
      "⏱  Took 107.43 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk037.mp3\n",
      "⏱  Took 112.57 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk106.mp3\n",
      "⏱  Took 111.52 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk063.mp3\n",
      "⏱  Took 116.19 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk135.mp3\n",
      "⏱  Took 106.65 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk103.mp3\n",
      "⏱  Took 115.78 seconds\n",
      "\n",
      "🔊 Transcribing: 006_chunk001.mp3\n",
      "⏱  Took 100.25 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk003.mp3\n",
      "⏱  Took 153.42 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk056.mp3\n",
      "⏱  Took 118.39 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk023.mp3\n",
      "⏱  Took 89.47 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk035.mp3\n",
      "⏱  Took 113.94 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk014.mp3\n",
      "⏱  Took 132.26 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk006.mp3\n",
      "⏱  Took 125.88 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk081.mp3\n",
      "⏱  Took 116.46 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk050.mp3\n",
      "⏱  Took 124.70 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk201.mp3\n",
      "⏱  Took 121.81 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk155.mp3\n",
      "⏱  Took 148.98 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk040.mp3\n",
      "⏱  Took 121.71 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk035.mp3\n",
      "⏱  Took 119.48 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk109.mp3\n",
      "⏱  Took 157.96 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk067.mp3\n",
      "⏱  Took 120.73 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk052.mp3\n",
      "⏱  Took 125.72 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk088.mp3\n",
      "⏱  Took 111.29 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk044.mp3\n",
      "⏱  Took 131.74 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk129.mp3\n",
      "⏱  Took 120.26 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk006.mp3\n",
      "⏱  Took 123.67 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk101.mp3\n",
      "⏱  Took 112.62 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk027.mp3\n",
      "⏱  Took 111.56 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk001.mp3\n",
      "⏱  Took 180.36 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk030.mp3\n",
      "⏱  Took 160.00 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk058.mp3\n",
      "⏱  Took 114.65 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk061.mp3\n",
      "⏱  Took 107.36 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk103.mp3\n",
      "⏱  Took 112.79 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk018.mp3\n",
      "⏱  Took 108.60 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk104.mp3\n",
      "⏱  Took 128.69 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk040.mp3\n",
      "⏱  Took 132.82 seconds\n",
      "\n",
      "🔊 Transcribing: 005_chunk002.mp3\n",
      "⏱  Took 65.72 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk021.mp3\n",
      "⏱  Took 135.48 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk018.mp3\n",
      "⏱  Took 135.67 seconds\n",
      "\n",
      "🔊 Transcribing: 007_chunk002.mp3\n",
      "⏱  Took 79.89 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk070.mp3\n",
      "⏱  Took 189.76 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk106.mp3\n",
      "⏱  Took 121.32 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk123.mp3\n",
      "⏱  Took 232.87 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk009.mp3\n",
      "⏱  Took 113.27 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk059.mp3\n",
      "⏱  Took 105.71 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk005.mp3\n",
      "⏱  Took 108.47 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk004.mp3\n",
      "⏱  Took 124.97 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk105.mp3\n",
      "⏱  Took 189.33 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk042.mp3\n",
      "⏱  Took 126.55 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk173.mp3\n",
      "⏱  Took 235.67 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk041.mp3\n",
      "⏱  Took 127.20 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk131.mp3\n",
      "⏱  Took 103.53 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk025.mp3\n",
      "⏱  Took 123.73 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk017.mp3\n",
      "⏱  Took 143.74 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk015.mp3\n",
      "⏱  Took 131.42 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk009.mp3\n",
      "⏱  Took 191.37 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk002.mp3\n",
      "⏱  Took 108.34 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk043.mp3\n",
      "⏱  Took 107.39 seconds\n",
      "\n",
      "🔊 Transcribing: 012_chunk001.mp3\n",
      "⏱  Took 123.21 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk047.mp3\n",
      "⏱  Took 120.76 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk071.mp3\n",
      "⏱  Took 104.56 seconds\n",
      "File saved successfully\n",
      "\n",
      "📊 Summary:\n",
      "Mean time: 129.59 s\n",
      "Min time : 65.72 s\n",
      "Max time : 342.53 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'test_whispercpp_large-v3.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../texts'\n",
    "model_name = \"large-v3\"\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in chosen_audio_list:\n",
    "    file_name = audio_f[\"audio\"] + \".mp3\"\n",
    "    audio_dir = \"../../metadata/chunks/audio\"\n",
    "    full_audio_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\n🔊 Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"⏱  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\n📊 Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74121428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔊 Transcribing: 013_chunk056.mp3\n",
      "⏱  Took 71.43 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk152.mp3\n",
      "⏱  Took 64.99 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk035.mp3\n",
      "⏱  Took 63.42 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk053.mp3\n",
      "⏱  Took 66.06 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk022.mp3\n",
      "⏱  Took 75.20 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk141.mp3\n",
      "⏱  Took 95.66 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk039.mp3\n",
      "⏱  Took 66.12 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk020.mp3\n",
      "⏱  Took 77.10 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk010.mp3\n",
      "⏱  Took 64.49 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk107.mp3\n",
      "⏱  Took 64.73 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk018.mp3\n",
      "⏱  Took 67.98 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk015.mp3\n",
      "⏱  Took 65.26 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk045.mp3\n",
      "⏱  Took 64.88 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk058.mp3\n",
      "⏱  Took 62.60 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk085.mp3\n",
      "⏱  Took 90.31 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk013.mp3\n",
      "⏱  Took 67.59 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk029.mp3\n",
      "⏱  Took 66.56 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk021.mp3\n",
      "⏱  Took 71.59 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk086.mp3\n",
      "⏱  Took 62.34 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk041.mp3\n",
      "⏱  Took 69.38 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk049.mp3\n",
      "⏱  Took 67.91 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk005.mp3\n",
      "⏱  Took 105.02 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk015.mp3\n",
      "⏱  Took 68.27 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk043.mp3\n",
      "⏱  Took 65.90 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk154.mp3\n",
      "⏱  Took 71.77 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk083.mp3\n",
      "⏱  Took 68.47 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk158.mp3\n",
      "⏱  Took 68.10 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk056.mp3\n",
      "⏱  Took 68.55 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk033.mp3\n",
      "⏱  Took 95.90 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk122.mp3\n",
      "⏱  Took 70.90 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk015.mp3\n",
      "⏱  Took 115.98 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk050.mp3\n",
      "⏱  Took 66.09 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk019.mp3\n",
      "⏱  Took 77.01 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk134.mp3\n",
      "⏱  Took 66.71 seconds\n",
      "\n",
      "🔊 Transcribing: 004_chunk005.mp3\n",
      "⏱  Took 62.89 seconds\n",
      "\n",
      "🔊 Transcribing: 002_chunk007.mp3\n",
      "⏱  Took 103.88 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk009.mp3\n",
      "⏱  Took 65.36 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk112.mp3\n",
      "⏱  Took 86.25 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk003.mp3\n",
      "⏱  Took 72.36 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk055.mp3\n",
      "⏱  Took 64.01 seconds\n",
      "\n",
      "🔊 Transcribing: 020_chunk037.mp3\n",
      "⏱  Took 65.75 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk106.mp3\n",
      "⏱  Took 62.73 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk063.mp3\n",
      "⏱  Took 72.19 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk135.mp3\n",
      "⏱  Took 60.45 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk103.mp3\n",
      "⏱  Took 64.68 seconds\n",
      "\n",
      "🔊 Transcribing: 006_chunk001.mp3\n",
      "⏱  Took 74.01 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk003.mp3\n",
      "⏱  Took 78.30 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk056.mp3\n",
      "⏱  Took 81.92 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk023.mp3\n",
      "⏱  Took 55.55 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk035.mp3\n",
      "⏱  Took 62.47 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk014.mp3\n",
      "⏱  Took 59.84 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk006.mp3\n",
      "⏱  Took 66.76 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk081.mp3\n",
      "⏱  Took 66.06 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk050.mp3\n",
      "⏱  Took 91.23 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk201.mp3\n",
      "⏱  Took 75.84 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk155.mp3\n",
      "⏱  Took 94.95 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk040.mp3\n",
      "⏱  Took 85.93 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk035.mp3\n",
      "⏱  Took 64.12 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk109.mp3\n",
      "⏱  Took 61.91 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk067.mp3\n",
      "⏱  Took 66.54 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk052.mp3\n",
      "⏱  Took 70.60 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk088.mp3\n",
      "⏱  Took 62.37 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk044.mp3\n",
      "⏱  Took 90.38 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk129.mp3\n",
      "⏱  Took 65.81 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk006.mp3\n",
      "⏱  Took 72.57 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk101.mp3\n",
      "⏱  Took 67.11 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk027.mp3\n",
      "⏱  Took 67.63 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk001.mp3\n",
      "⏱  Took 80.22 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk030.mp3\n",
      "⏱  Took 68.06 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk058.mp3\n",
      "⏱  Took 64.29 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk061.mp3\n",
      "⏱  Took 87.23 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk103.mp3\n",
      "⏱  Took 74.61 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk018.mp3\n",
      "⏱  Took 70.62 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk104.mp3\n",
      "⏱  Took 84.09 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk040.mp3\n",
      "⏱  Took 73.84 seconds\n",
      "\n",
      "🔊 Transcribing: 005_chunk002.mp3\n",
      "⏱  Took 88.75 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk021.mp3\n",
      "⏱  Took 80.73 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk018.mp3\n",
      "⏱  Took 76.77 seconds\n",
      "\n",
      "🔊 Transcribing: 007_chunk002.mp3\n",
      "⏱  Took 67.58 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk070.mp3\n",
      "⏱  Took 102.05 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk106.mp3\n",
      "⏱  Took 79.09 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk123.mp3\n",
      "⏱  Took 85.78 seconds\n",
      "\n",
      "🔊 Transcribing: 022_chunk009.mp3\n",
      "⏱  Took 64.19 seconds\n",
      "\n",
      "🔊 Transcribing: 016_chunk059.mp3\n",
      "⏱  Took 83.95 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk005.mp3\n",
      "⏱  Took 79.32 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk004.mp3\n",
      "⏱  Took 79.61 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk105.mp3\n",
      "⏱  Took 76.31 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk042.mp3\n",
      "⏱  Took 75.18 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk173.mp3\n",
      "⏱  Took 74.84 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk041.mp3\n",
      "⏱  Took 72.87 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk131.mp3\n",
      "⏱  Took 77.80 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk025.mp3\n",
      "⏱  Took 106.30 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk017.mp3\n",
      "⏱  Took 68.72 seconds\n",
      "\n",
      "🔊 Transcribing: 019_chunk015.mp3\n",
      "⏱  Took 113.50 seconds\n",
      "\n",
      "🔊 Transcribing: 021_chunk009.mp3\n",
      "⏱  Took 66.05 seconds\n",
      "\n",
      "🔊 Transcribing: 008_chunk002.mp3\n",
      "⏱  Took 55.21 seconds\n",
      "\n",
      "🔊 Transcribing: 018_chunk043.mp3\n",
      "⏱  Took 74.70 seconds\n",
      "\n",
      "🔊 Transcribing: 012_chunk001.mp3\n",
      "⏱  Took 84.58 seconds\n",
      "\n",
      "🔊 Transcribing: 017_chunk047.mp3\n",
      "⏱  Took 71.58 seconds\n",
      "\n",
      "🔊 Transcribing: 013_chunk071.mp3\n",
      "⏱  Took 79.59 seconds\n",
      "File saved successfully\n",
      "\n",
      "📊 Summary:\n",
      "Mean time: 74.25 s\n",
      "Min time : 55.21 s\n",
      "Max time : 115.98 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'test_whispercpp_turbo.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../texts_turbo'\n",
    "model_name = \"turbo\"\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in chosen_audio_list:\n",
    "    file_name = audio_f[\"audio\"] + \".mp3\"\n",
    "    audio_dir = \"../../metadata/chunks/audio\"\n",
    "    full_audio_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\n🔊 Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"⏱  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\n📊 Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1de36",
   "metadata": {},
   "source": [
    "## Whispercpp Large-v3 stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad458b68",
   "metadata": {},
   "source": [
    "📊 Summary:\n",
    "Mean time: 129.59 s\n",
    "Min time : 65.72 s\n",
    "Max time : 342.53 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39ae7",
   "metadata": {},
   "source": [
    "## Whispercpp Turbo stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b1a15",
   "metadata": {},
   "source": [
    "📊 Summary:\n",
    "Mean time: 74.25 s\n",
    "Min time : 55.21 s\n",
    "Max time : 115.98 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffc6a4",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Turbo model is x1.75 faster </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d45e6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebeb293",
   "metadata": {},
   "source": [
    "The transcriptions are saved in **json/test_whisper_(model).json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57eaec",
   "metadata": {},
   "source": [
    "## Manual Evaluation\n",
    "We evaluate the quality of transcriptions manually\n",
    "- 013_chunk056: Turbo clearly better\n",
    "- 017_chunk152: Large is mixing sentnce order, Turbo is good\n",
    "- 013_chunk035: Kinda the same quality, both good\n",
    "- 008_chunk022: Both are bad and misses a portion of speech\n",
    "- 020_chunk039: Turbo is good, Large is same\n",
    "- 016_chunk010: Turbo is good but mixes sentences, Large is good\n",
    "- 022_chunk015: both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f844b3",
   "metadata": {},
   "source": [
    "## Numerical Evaluation(cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6e92b",
   "metadata": {},
   "source": [
    "we load the both transcription data, with youtube(original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be968179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whispercpp_turbo.json'\n",
    "whisper_large_t = '../json/test_whispercpp_large-v3.json'\n",
    "# original_t = '../json/text_audio_mapping.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n",
    "\n",
    "# with open(original_t, 'r') as f:\n",
    "#     original_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c07c97",
   "metadata": {},
   "source": [
    "### Generate embeddings for whisper transcriptions and save them in new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55411129",
   "metadata": {},
   "source": [
    "Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f4a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "your_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911b212",
   "metadata": {},
   "source": [
    "Generating embedding using OpenAI multilingual transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# we use 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def add_embeddings(data_list, text_key):\n",
    "    \"\"\"\n",
    "    Generates and adds embeddings for each item in a list of dictionaries.\n",
    "\n",
    "    Args: \n",
    "        data_list (list): A list of dictionaries, where each dict has a text field.\n",
    "        text_key (str): The key for the text field in each dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list with an '_embedding' key added to each dictionary.\n",
    "    \"\"\"\n",
    "    texts = [item.get(text_key) for item in data_list]\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "\n",
    "    for i, item in enumerate(data_list):\n",
    "        new_key = text_key + '_embedding'\n",
    "        item[new_key] = embeddings[i].tolist() # Convert numpy array to list for JSON serialization\n",
    "\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317cdd34",
   "metadata": {},
   "source": [
    "save in a different file for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11855735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turbo_embeddings_path = '../json/turbo_cpp_embeddings.json'\n",
    "large_embeddings_path = '../json/large_cpp_embeddings.json'\n",
    "\n",
    "origial_embeddings_path = '../json/origial_embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33093e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_embeddings = add_embeddings(turbo_transcriptions, \"transcription\")\n",
    "large_embeddings = add_embeddings(large_transcriptions, \"transcription\")\n",
    "\n",
    "\n",
    "with open(turbo_embeddings_path, 'w') as f:\n",
    "    json.dump(turbo_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(large_embeddings_path, 'w') as f:\n",
    "    json.dump(large_embeddings, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619c1b1",
   "metadata": {},
   "source": [
    "## Apply cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b6afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(turbo_embeddings_path, 'r') as f:\n",
    "    turbo_embeddings = json.load(f)\n",
    "\n",
    "with open(large_embeddings_path, 'r') as f:\n",
    "    large_embeddings = json.load(f)\n",
    "\n",
    "with open(origial_embeddings_path, 'r') as f:\n",
    "    original_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8472b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_file = '../json/turbo_cpp_vs_large.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7565e",
   "metadata": {},
   "source": [
    "Apply cosine similarity and save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad2f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for row in original_embeddings:\n",
    "    original_emb = row['text_embedding']\n",
    "    turbo_emb = next((f['transcription_embedding'] for f in turbo_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "    large_emb = next((f['transcription_embedding'] for f in large_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "\n",
    "    if not turbo_emb:\n",
    "        print(f\"NOT FOUND turbo embedding for file {row['audio']}\")\n",
    "\n",
    "    if not large_emb:\n",
    "        print(f\"NOT FOUND large embedding for file {row['audio']}\")\n",
    "    original_emb = np.array(original_emb).reshape(1, -1)\n",
    "    turbo_emb = np.array(turbo_emb).reshape(1, -1)\n",
    "    large_emb = np.array(large_emb).reshape(1, -1)\n",
    "\n",
    "    turbo_cosine = cosine_similarity(original_emb, turbo_emb)[0][0]\n",
    "    large_cosine = cosine_similarity(original_emb, large_emb)[0][0]\n",
    "\n",
    "    metric_list.append({\n",
    "        \"audio\": row['audio'],\n",
    "        'turbo_cosine': turbo_cosine,\n",
    "        'large_cosine': large_cosine\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metric_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17240307",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afa3ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>turbo_cosine</th>\n",
       "      <th>large_cosine</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_chunk007</td>\n",
       "      <td>0.924972</td>\n",
       "      <td>0.874039</td>\n",
       "      <td>-0.050933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_chunk018</td>\n",
       "      <td>0.939545</td>\n",
       "      <td>0.949126</td>\n",
       "      <td>0.009581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_chunk019</td>\n",
       "      <td>0.956090</td>\n",
       "      <td>0.927396</td>\n",
       "      <td>-0.028694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_chunk005</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.021302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_chunk002</td>\n",
       "      <td>0.712337</td>\n",
       "      <td>0.313424</td>\n",
       "      <td>-0.398913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>022_chunk009</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>0.873117</td>\n",
       "      <td>-0.112661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>022_chunk015</td>\n",
       "      <td>0.971704</td>\n",
       "      <td>0.979342</td>\n",
       "      <td>0.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>022_chunk027</td>\n",
       "      <td>0.967482</td>\n",
       "      <td>0.826178</td>\n",
       "      <td>-0.141304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>022_chunk035</td>\n",
       "      <td>0.908721</td>\n",
       "      <td>0.945594</td>\n",
       "      <td>0.036873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>022_chunk055</td>\n",
       "      <td>0.883070</td>\n",
       "      <td>0.901589</td>\n",
       "      <td>0.018518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio  turbo_cosine  large_cosine  difference\n",
       "0   002_chunk007      0.924972      0.874039   -0.050933\n",
       "1   002_chunk018      0.939545      0.949126    0.009581\n",
       "2   002_chunk019      0.956090      0.927396   -0.028694\n",
       "3   004_chunk005      0.942761      0.964063    0.021302\n",
       "4   005_chunk002      0.712337      0.313424   -0.398913\n",
       "..           ...           ...           ...         ...\n",
       "95  022_chunk009      0.985778      0.873117   -0.112661\n",
       "96  022_chunk015      0.971704      0.979342    0.007638\n",
       "97  022_chunk027      0.967482      0.826178   -0.141304\n",
       "98  022_chunk035      0.908721      0.945594    0.036873\n",
       "99  022_chunk055      0.883070      0.901589    0.018518\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Comparison for CPU ---\n",
      "turbo_mean: 0.916271\n",
      "large_mean: 0.916341\n",
      "turbo_std: 0.096982\n",
      "large_std: 0.092034\n",
      "avg_difference: 0.000070\n",
      "turbo_better_count: 52.000000\n",
      "large_better_count: 48.000000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metric_list = json.load(f)\n",
    "\n",
    "# put into DataFrame\n",
    "df = pd.DataFrame(metric_list)\n",
    "\n",
    "# compute difference\n",
    "df[\"difference\"] = df[\"large_cosine\"] - df[\"turbo_cosine\"]\n",
    "\n",
    "# summary statistics\n",
    "summary = {\n",
    "    \"turbo_mean\": df[\"turbo_cosine\"].mean(),\n",
    "    \"large_mean\": df[\"large_cosine\"].mean(),\n",
    "    \"turbo_std\": df[\"turbo_cosine\"].std(),\n",
    "    \"large_std\": df[\"large_cosine\"].std(),\n",
    "    \"avg_difference\": df[\"difference\"].mean(),\n",
    "    \"turbo_better_count\": (df[\"difference\"] < 0).sum(),\n",
    "    \"large_better_count\": (df[\"difference\"] > 0).sum()\n",
    "}\n",
    "\n",
    "display(df)\n",
    "print(\"\\n--- Summary Comparison for CPU ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ea505",
   "metadata": {},
   "source": [
    "# Whisper Large on low quality audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c857879",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b3b93",
   "metadata": {},
   "source": [
    "## CPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6051b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LOW_AUDIO_FOLDER = r\"C:\\Users\\ACER\\Desktop\\ASR\\code-low\\raw_audio\"\n",
    "low_audio_files =[f for f in os.listdir(LOW_AUDIO_FOLDER) if f.endswith(\".mp3\") and f.startswith(\"0\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cf2efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔊 Transcribing: 001.mp3\n",
      "⏱  Took 590.45 seconds\n",
      "\n",
      "🔊 Transcribing: 002.mp3\n",
      "⏱  Took 1583.96 seconds\n",
      "\n",
      "🔊 Transcribing: 003.mp3\n",
      "⏱  Took 912.35 seconds\n",
      "\n",
      "🔊 Transcribing: 004.mp3\n",
      "⏱  Took 347.04 seconds\n",
      "File saved successfully\n",
      "\n",
      "📊 Summary:\n",
      "Mean time: 858.45 s\n",
      "Min time : 347.04 s\n",
      "Max time : 1583.96 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'low_quality_test_whispercpp_large-v3.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../low_texts'\n",
    "model_name = \"large-v3\"\n",
    "saving_dir = '../json'\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in low_audio_files:\n",
    "    file_name = audio_f\n",
    "    full_audio_path = os.path.join(LOW_AUDIO_FOLDER, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\n🔊 Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"⏱  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\n📊 Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38226b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_key = os.getenv(\"GEMINI_KEY\")\n",
    "\n",
    "# Configure gemini API key\n",
    "genai.configure(api_key=gemini_key)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash',generation_config={\n",
    "    \"temperature\": 0.2,\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1697fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "classes = [\"comedy\", \"business\", \"cars\", \"tourism\", \"stories\"]\n",
    "\n",
    "\n",
    "def classify_text(text, language = \"algerian\"):\n",
    "    \n",
    "    prompt = (\n",
    "        f\"The following {language} text may include more than one speaker. \"\n",
    "        f\"Understand the general topics, and based on that classify this text into: {classes}. \"\n",
    "        f\"Allow multiple classes and return only a Python list \"\n",
    "        f\"(response must start with [ and end with ]). \\nText:\\n{text}\"\n",
    "    )\n",
    "    try:\n",
    "        raw = model.generate_content(prompt).text\n",
    "        result_classes = ast.literal_eval(raw)\n",
    "        \n",
    "        return result_classes\n",
    "    except Exception:\n",
    "        print(\"Error during text classification\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368875e5",
   "metadata": {},
   "source": [
    "### Classify the Turbo and Large-v3 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70afa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whispercpp_turbo.json'\n",
    "whisper_large_t = '../json/test_whispercpp_large-v3.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414cd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_refinement_prompt = \"\"\" You are an expert in Algerian Arabic (Darja).  \n",
    "Your task is to proofread the following text.  \n",
    "\n",
    "- understand and keep the original context, \n",
    "- Correct spelling mistakes.  \n",
    "- Fix spacing (remove extra spaces, add missing spaces).  \n",
    "- Do NOT change the sentence structure or meaning, \n",
    "  and do not add extra words that are not in the sentence. \n",
    "- Keep the natural Darja style and tone and emotions\n",
    "\n",
    "Return only the corrected text. here's the text: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "169375af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comedy', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'cars']\n",
      "['comedy']\n",
      "['tourism', 'stories']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['cars', 'business']\n",
      "['business', 'stories']\n",
      "['comedy', 'stories', 'business']\n",
      "['business', 'stories']\n",
      "['stories', 'business', 'comedy']\n",
      "['stories', 'comedy']\n",
      "['stories']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['stories']\n",
      "['comedy', 'business']\n",
      "['comedy', 'stories']\n",
      "['business', 'cars', 'stories']\n",
      "['comedy', 'business']\n",
      "['business']\n",
      "['stories', 'comedy']\n"
     ]
    }
   ],
   "source": [
    "for row in turbo_transcriptions[:30]:\n",
    "    try:\n",
    "        text = row['transcription']\n",
    "        full_prompt = base_refinement_prompt + text\n",
    "        refined = model.generate_content(full_prompt).text\n",
    "        result = classify_text(refined)\n",
    "\n",
    "        row['refined'] = refined\n",
    "        row['classes'] = result\n",
    "\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "with open(whisper_turbo_t, 'w') as f:\n",
    "    json.dump(turbo_transcriptions, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65caa17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comedy', 'stories']\n",
      "['business', 'stories']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'cars']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['tourism']\n",
      "['business', 'tourism']\n",
      "['stories']\n",
      "['comedy', 'business']\n",
      "['stories', 'business']\n",
      "['stories']\n",
      "['stories']\n",
      "['business', 'stories']\n",
      "['stories', 'comedy']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['comedy', 'business']\n",
      "['business', 'stories']\n",
      "['business']\n",
      "['comedy', 'stories']\n"
     ]
    }
   ],
   "source": [
    "for row in large_transcriptions[:30]:\n",
    "    try:\n",
    "        text = row['transcription']\n",
    "        full_prompt = base_refinement_prompt + text\n",
    "        refined = model.generate_content(full_prompt).text\n",
    "        result = classify_text(refined)\n",
    "\n",
    "        row['refined'] = refined\n",
    "        row['classes'] = result\n",
    "\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "with open(whisper_large_t, 'w') as f:\n",
    "    json.dump(large_transcriptions, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d5279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
