{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1774a07d",
   "metadata": {},
   "source": [
    "# Benchmark and compare Whisper models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53315d",
   "metadata": {},
   "source": [
    "In this notebook, we try to apply transcription and classification with \n",
    "\n",
    "Whisper (Large vs Turbo, CPP AND GPU versions) and Analyse the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b50ca",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74716fe",
   "metadata": {},
   "source": [
    "We start with generating transcription with both models(turbo and large-v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf586a2",
   "metadata": {},
   "source": [
    "Let's choose a sample of random audios(100 units), so we make sure our sample is representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a938d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# audio_folder = '../../metadata/chunks/audio' \n",
    "# transcriptions_file = '../../metadata/chunks/text_audio_mapping.json'\n",
    "# saving_file = '../json/selected_audio_files.json'\n",
    "# AUDIO_NUM = 100\n",
    "\n",
    "# audio_files = os.listdir(audio_folder)\n",
    "# random.shuffle(audio_files)\n",
    "\n",
    "# selected_audio_files = audio_files[:AUDIO_NUM]\n",
    "\n",
    "# # add original transcriptions\n",
    "# data = None\n",
    "# with open(transcriptions_file, 'r') as f:\n",
    "#     transcriptions = json.load(f)\n",
    "\n",
    "# json_objects = []\n",
    "\n",
    "# for file in selected_audio_files:\n",
    "#     audio_name = file.replace(\".mp3\", \"\")\n",
    "#     transcription = next(t['text'] for t in transcriptions if t['audio'] == audio_name )\n",
    "#     json_objects.append(\n",
    "#         {\n",
    "#             \"audio\": audio_name,\n",
    "#             \"transcription\": transcription\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# with open(saving_file, 'w') as f:\n",
    "#     json.dump(json_objects, f, ensure_ascii=False)\n",
    "\n",
    "# print(selected_audio_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c0f2",
   "metadata": {},
   "source": [
    "We will transcribe these audio files using Whisper Large-v3 and Turbo and see the quality and time\n",
    "\n",
    "This will run in colab Tesla T4 (12.7 GB VRAM as the runtime shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86096e5b",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae61c18",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats (first run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec241",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ“Š Summary:\n",
    "\n",
    "Mean time: 27.55 s\n",
    "Min time : 7.81 s\n",
    "Max time : 101.91 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058386f5",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats(second run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddce50",
   "metadata": {},
   "source": [
    "ğŸ“Š Summary:\n",
    "Mean time: 26.32 s\n",
    "Min time : 9.90 s\n",
    "Max time : 64.60 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d388c5",
   "metadata": {},
   "source": [
    "## Whisper Turbo stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e8132",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ“Š Summary:\n",
    "Mean time: 8.86 s\n",
    "Min time : 3.21 s\n",
    "Max time : 21.19 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5e82f",
   "metadata": {},
   "source": [
    "### <span style='color:blue'> *Turbo is more that x3 times faster than Large* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94e50e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01f578",
   "metadata": {},
   "source": [
    "The transcriptions are saved in **json/test_whisper_(model).json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac2951",
   "metadata": {},
   "source": [
    "## Manual Evaluation\n",
    "We evaluate the quality of transcriptions manually\n",
    "- 013_chunk056: Turbo much better\n",
    "- 017_chunk152: Large is horrible, Turbo is good\n",
    "- 013_chunk035: Kinda the same quality, both good\n",
    "- 008_chunk022: Large misses a portion of speech, Turbo is worse\n",
    "- 020_chunk039: Turbo is good, Large is same\n",
    "- 016_chunk010: Large is better\n",
    "- 022_chunk015: both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceec0b9",
   "metadata": {},
   "source": [
    "## Numerical Evaluation(cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aecb1f",
   "metadata": {},
   "source": [
    "we load the both transcription data, with youtube(original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a1a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whisper_turbo.json'\n",
    "whisper_large_t = '../json/test_whisper_large-v3.json'\n",
    "original_t = '../json/text_audio_mapping.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n",
    "\n",
    "with open(original_t, 'r') as f:\n",
    "    original_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068788e",
   "metadata": {},
   "source": [
    "Filter originals list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43aebb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick test: length of filtered list: 100\n"
     ]
    }
   ],
   "source": [
    "# load chosen audio list\n",
    "chosen_audio_f = '../json/selected_audio_files.json'\n",
    "original_filtered = []\n",
    "\n",
    "with open(chosen_audio_f, 'r') as f:\n",
    "    chosen_audio_list = json.load(f)\n",
    "for row in original_transcriptions:\n",
    "    found = next((1 for f in chosen_audio_list if f['audio'] == row['audio']), None)\n",
    "    if found:\n",
    "        original_filtered.append(row)\n",
    "\n",
    "print(f\"quick test: length of filtered list: {len(original_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb72cdf",
   "metadata": {},
   "source": [
    "### Generate embeddings for whisper transcriptions and save them in new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b29c5",
   "metadata": {},
   "source": [
    "Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b360f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "your_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8493ee5",
   "metadata": {},
   "source": [
    "Generating embedding using OpenAI multilingual transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff3f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# we use 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def add_embeddings(data_list, text_key):\n",
    "    \"\"\"\n",
    "    Generates and adds embeddings for each item in a list of dictionaries.\n",
    "\n",
    "    Args: \n",
    "        data_list (list): A list of dictionaries, where each dict has a text field.\n",
    "        text_key (str): The key for the text field in each dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list with an '_embedding' key added to each dictionary.\n",
    "    \"\"\"\n",
    "    texts = [item.get(text_key) for item in data_list]\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "\n",
    "    for i, item in enumerate(data_list):\n",
    "        new_key = text_key + '_embedding'\n",
    "        item[new_key] = embeddings[i].tolist() # Convert numpy array to list for JSON serialization\n",
    "\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d1e97",
   "metadata": {},
   "source": [
    "save in a different file for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa74dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turbo_embeddings_path = '../json/turbo_embeddings.json'\n",
    "large_embeddings_path = '../json/large_embeddings.json'\n",
    "origial_embeddings_path = '../json/origial_embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_embeddings = add_embeddings(turbo_transcriptions, \"transcription\")\n",
    "large_embeddings = add_embeddings(large_transcriptions, \"transcription\")\n",
    "original_embeddings = add_embeddings(original_filtered, \"text\")\n",
    "\n",
    "\n",
    "with open(turbo_embeddings_path, 'w') as f:\n",
    "    json.dump(turbo_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(large_embeddings_path, 'w') as f:\n",
    "    json.dump(large_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(origial_embeddings_path, 'w') as f:\n",
    "    json.dump(original_embeddings, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c44639",
   "metadata": {},
   "source": [
    "## Apply cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9356a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(turbo_embeddings_path, 'r') as f:\n",
    "    turbo_embeddings = json.load(f)\n",
    "\n",
    "with open(large_embeddings_path, 'r') as f:\n",
    "    large_embeddings = json.load(f)\n",
    "\n",
    "with open(origial_embeddings_path, 'r') as f:\n",
    "    original_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196033d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_file = '../json/turbo_vs_large.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51a5dd",
   "metadata": {},
   "source": [
    "Apply cosine similarity and save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0767f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for row in original_embeddings:\n",
    "    original_emb = row['text_embedding']\n",
    "    turbo_emb = next((f['transcription_embedding'] for f in turbo_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "    large_emb = next((f['transcription_embedding'] for f in large_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "\n",
    "    if not turbo_emb:\n",
    "        print(f\"NOT FOUND turbo embedding for file {row['audio']}\")\n",
    "\n",
    "    if not large_emb:\n",
    "        print(f\"NOT FOUND large embedding for file {row['audio']}\")\n",
    "    original_emb = np.array(original_emb).reshape(1, -1)\n",
    "    turbo_emb = np.array(turbo_emb).reshape(1, -1)\n",
    "    large_emb = np.array(large_emb).reshape(1, -1)\n",
    "\n",
    "    turbo_cosine = cosine_similarity(original_emb, turbo_emb)[0][0]\n",
    "    large_cosine = cosine_similarity(original_emb, large_emb)[0][0]\n",
    "\n",
    "    metric_list.append({\n",
    "        \"audio\": row['audio'],\n",
    "        'turbo_cosine': turbo_cosine,\n",
    "        'large_cosine': large_cosine\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metric_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6b40c",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bdcd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>turbo_cosine</th>\n",
       "      <th>large_cosine</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_chunk007</td>\n",
       "      <td>0.957282</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>-0.028034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_chunk018</td>\n",
       "      <td>0.953961</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>-0.020346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_chunk019</td>\n",
       "      <td>0.894270</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.049578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_chunk005</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.940228</td>\n",
       "      <td>0.036657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_chunk002</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.950694</td>\n",
       "      <td>-0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>022_chunk009</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.833761</td>\n",
       "      <td>-0.154815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>022_chunk015</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.876124</td>\n",
       "      <td>-0.089463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>022_chunk027</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>0.012392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>022_chunk035</td>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.886476</td>\n",
       "      <td>-0.020563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>022_chunk055</td>\n",
       "      <td>0.842067</td>\n",
       "      <td>0.937556</td>\n",
       "      <td>0.095489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio  turbo_cosine  large_cosine  difference\n",
       "0   002_chunk007      0.957282      0.929248   -0.028034\n",
       "1   002_chunk018      0.953961      0.933615   -0.020346\n",
       "2   002_chunk019      0.894270      0.943848    0.049578\n",
       "3   004_chunk005      0.903571      0.940228    0.036657\n",
       "4   005_chunk002      0.972451      0.950694   -0.021757\n",
       "..           ...           ...           ...         ...\n",
       "95  022_chunk009      0.988576      0.833761   -0.154815\n",
       "96  022_chunk015      0.965587      0.876124   -0.089463\n",
       "97  022_chunk027      0.908584      0.920975    0.012392\n",
       "98  022_chunk035      0.907040      0.886476   -0.020563\n",
       "99  022_chunk055      0.842067      0.937556    0.095489\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Comparison ---\n",
      "turbo_mean: 0.9261\n",
      "large_mean: 0.9148\n",
      "turbo_std: 0.0809\n",
      "large_std: 0.0644\n",
      "avg_difference: -0.0113\n",
      "turbo_better_count: 66.0000\n",
      "large_better_count: 34.0000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metric_list = json.load(f)\n",
    "\n",
    "# put into DataFrame\n",
    "df = pd.DataFrame(metric_list)\n",
    "\n",
    "# compute difference\n",
    "df[\"difference\"] = df[\"large_cosine\"] - df[\"turbo_cosine\"]\n",
    "\n",
    "# summary statistics\n",
    "summary = {\n",
    "    \"turbo_mean\": df[\"turbo_cosine\"].mean(),\n",
    "    \"large_mean\": df[\"large_cosine\"].mean(),\n",
    "    \"turbo_std\": df[\"turbo_cosine\"].std(),\n",
    "    \"large_std\": df[\"large_cosine\"].std(),\n",
    "    \"avg_difference\": df[\"difference\"].mean(),\n",
    "    \"turbo_better_count\": (df[\"difference\"] < 0).sum(),\n",
    "    \"large_better_count\": (df[\"difference\"] > 0).sum()\n",
    "}\n",
    "\n",
    "display(df)\n",
    "print(\"\\n--- Summary Comparison ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddd808",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Turbo model looks much better for this test unit </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a540c3",
   "metadata": {},
   "source": [
    "# **CPU Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7563e97",
   "metadata": {},
   "source": [
    "function to transcribe audio using the cpp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d39a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def transcribe_audio(\n",
    "    audio_path,\n",
    "    text_output_dir,\n",
    "    exe_path,\n",
    "    model_name=\"large-v3\",\n",
    "    language=\"ar\",\n",
    "    threads=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Whisper.cpp on a given audio file and store the .txt output\n",
    "    in a separate folder (text_output_dir).\n",
    "    Returns the transcribed text.\n",
    "    \"\"\"\n",
    "    model_path = r\"C:\\Users\\ACER\\whisper.cpp\\models\\ggml-\" + model_name + \".bin\" \n",
    "    audio_path = Path(audio_path)\n",
    "    text_output_dir = Path(text_output_dir)\n",
    "    text_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Use the audio file name but save inside text_output_dir\n",
    "    # Corrected path handling\n",
    "    txt_output = text_output_dir / audio_path.stem  # no extension here\n",
    "\n",
    "    cmd = [\n",
    "        exe_path,\n",
    "        \"-m\", model_path,\n",
    "        \"-f\", str(audio_path),\n",
    "        \"-l\", language,\n",
    "        \"-t\", str(threads),\n",
    "        \"-otxt\",\n",
    "        \"-of\", str(txt_output)  # whisper.cpp will add .txt automatically\n",
    "    ]\n",
    "\n",
    "    final_txt_file = txt_output.with_suffix(\".txt\")\n",
    "\n",
    "    subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if final_txt_file.exists():\n",
    "        return final_txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda044a",
   "metadata": {},
   "source": [
    "get the sample of audio files that we already chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fc4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'audio': '013_chunk056', 'transcription': 'Ø¬Ùˆ Ø³ÙˆÙŠ Ø³ÙˆØ± ÙƒØ§ÙŠÙ†ÙŠÙ† Ø­ØªÙ‰ ÙÙŠÙ„Ø§Ù„Ø¬ÙŠØ±ÙŠØ§ ÙƒØ§ÙŠÙ† ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… ÙƒØ§Ù…Ù„ ÙˆØ§Ø­Ø¯ Ø§Ù„Ù†Ø§Ø³ ÙƒÙŠØªØ²Ø§Ø¯ÙˆØ§ ØªÙŠØ­Ø³ Ø¨Ø±Ø§Ø³Ù‡ Ø§Ù† Ù…Ù„ÙŠ ÙƒÙ†Øª ÙƒÙ†Ø´Ø¹Ù„ Ø§Ù„ØªÙ„ÙØ§Ø²Ù‡ Ù…Ø§ ÙƒØ§Ù†ØªØ´ ÙƒØªØ¹Ù†ÙŠ Ù„ÙŠ Ø´ÙŠ Ø­Ø§Ø¬Ù‡ Ù‡Ø°ÙˆÙƒ Ø±Ø§Ù‡ Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ù‡Ø§ Ø§Ù‡ Ø§Ø­Ù†Ø§ Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ù„ÙŠ Ù„Ù‡ÙŠÙ‡ ÙÙ‡Ù…ØªÙŠ Ù‡Ø°Ùˆ Ø±Ø§Ù‡ ÙƒØ§ÙŠÙ†ÙŠÙ† ÙƒØ§ÙŠÙ†ÙŠÙ† ÙÙŠ Ø§Ù„Ø¹Ø§ØµÙ…Ù‡ Ø­Ù†Ø§ Ø´Ø¹Ø¨ÙˆÙ† Ø«Ø§Ù†ÙŠ Ø§Ù‡ Ø§Ù‡ ÙÙ‡Ù…ØªÙŠ Ù…Ø§ØªÙŠØ¹Ù†ÙŠÙˆÙ†ÙŠØ´ Ø§Ù„Ø·Ø±ÙŠÙ‚Ù‡ Ø¨Ø§Ø´ ÙƒÙŠÙ„Ø¨Ø³ÙˆØ§ Ù„Ø§Ø¨Ø³ ÙƒÙˆØ³ØªÙŠÙˆÙ… Ø®ØªÙ†Ø§ Ù„Ø§Ø¨Ø³Ù‡ ÙÙŠØ³Øª ÙƒØ°Ø§ Ù„Ø§ Ø¹Ù„Ø§Ù‚Ù‡ Ù…Ø§ Ø¹Ù†Ø¯ÙƒØ´ Ù„Ø§Ø¨Ø§Ø±ØªÙˆÙ†ÙˆÙ†Ø³ Ù„Ù‡Ø°Ùƒ Ù„Ø§ Ø¹Ù„Ø§Ù‚Ù‡ Ø§Ù†Ø§ ØªÙ†Ø¹Ø±Ù Ø§Ù„ÙƒØ§Ø±ØªÙŠ Ø¯ÙŠØ§Ù„Ù†Ø§ 200 Ø¯ÙˆÙ„Ø§Ø± Ø§Ø®Ø§ÙŠ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙŠ Ø§Ù„Ù„ÙŠ Ø´Ù†Ùˆ ÙŠÙ‚Ø¯Ø± ÙŠØ¯ÙŠØ± Ø¨ 200 Ø¯ÙˆÙ„Ø§Ø± Ø§Ù„Ù‡Ø¶Ø±Ù‡ Ø¯ÙŠØ§Ù„ Ø§Ù„ØµØ§Ùƒ ÙƒØ§Ù…Ù„Ù‡ ØµØ­ÙŠØ­Ù‡ ØºÙŠØ± Ø§Ù†Ø§ÙŠØ§ Ø¯ÙŠ Ù†Ø²Ù„ Ù„Ù„ØªÙŠØ±Ø§Ù† ÙˆØ±Ø§ Ù…Ø§ Ù…Ø­ØªØ§Ø¬Ø´ Ù„ 200 Ø¯ÙˆÙ„Ø§Ø± ÙƒØ§ÙŠÙ† ÙŠÙ‚Ø¯Ø± Ù…Ø§ Ù†Ø­ØªØ§Ø¬Ø´ Ù…Ø§ Ù‚Ø§Ù„ Ù…Ø§ Ù†Ø­ØªØ§Ø¬ Ø­ØªØ§Ø¬Ø´ ÙƒØ§Ø¹ 200 Ø¯ÙˆÙ„Ø§Ø± Ø§Ù†Ø§ Ø­ Ø§Ù†Ø§ Ù†Ù‚Ø¯Ø± Ù†Ø²Ù„ Ù„Ù„Ø³ÙˆÙ‚ Ù†Ø¯ÙŠØ± Ø§Ù„ØªØ±Ø¬Ù…Ù‡ Ù†Ø­Ù„ ÙØ§ÙŠÙØ± Ø´ÙˆÙ Ø´Ù†Ùˆ Ø§Ù„Ù„ÙŠ Ù…Ø´ÙŠ ÙˆØ§Ø´ Ù†Ù‚Ø¯Ø± Ù†Ø¯ÙŠØ± Ù‡Ø°Ø§ Ù„ÙŠÙ…Ø§Ø¬ Ø§ÙŠØ¯ÙŠØªÙŠÙ†Øº Ø§Ù„Ù„ÙŠ Ø·Ø§Ù„Ø¨ÙŠÙ† ØºÙ†Ù…Ø´ÙŠ Ù†Ø²Ø­Ù… Ù‡Ø°Ø§ Ø­Ù‰ Ø§Ù†Ø§ Ù†Ø¯ÙŠØ± Ù…Ø¹Ù‡ Ø§Ù„Ù…Ù†Ø§ÙØ³Ù‡ Ù‡Ùˆ ÙƒÙŠØ·Ù„Ø¨ 50 Ø¯ÙˆÙ„Ø§Ø± ÙØ§ÙŠÙØ± Ø§Ù†Ø§ Ø§Ø®ÙˆÙŠØ§ Ù†Ø¯ÙŠØ± ØºÙŠØ± Ø¨ 5 Ø¯ÙˆÙ„Ø§Ø± Ø§Ù†Ø§ Ù…Ø³Ø§Ù„ÙŠ Ù…Ø§ Ø¹Ù†Ø¯ÙŠ Ù…Ø§ Ù†Ø¯ÙŠØ± 5 Ø¯ÙˆÙ„Ø§Ø± ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ø¬Ø²Ø§Ø¦Ø± Ø±Ø§Ù‡ Ø´ÙŠ Ø­Ø§Ø¬Ù‡ Ø§ 120 ÙˆÙ„Ø§ ØµØ§ÙØ§ Ø±Ø§'}, {'audio': '017_chunk152', 'transcription': 'Ø§Ù„ÙƒÙˆÙ†Øª Ø¨ÙŠØ¨Ù„ÙŠØ³ÙŠØªÙŠØ± Ù‡Ø°Ø§Ùƒ Ù‚Ø¯ Ù…Ø§ ØªØ³ØªÙ‚ÙˆÙ‰ Ù‚Ø¯ Ù…Ø§ Ù‡Ùˆ ÙŠØ³ÙŠØ¨Ù„ÙŠ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ ÙˆØ§Ø´ Ø¹Ù†Ø¯Ù‡ Ø¯Ø·Ø§ ÙˆÙƒØ§ÙŠÙ† Ø·Ø±Ù‚ Ø¨Ø§Ø´ Ù†Ø§Ù„ÙˆÙ†ØªÙŠ Ø§Ù„Ø¯Ø§Ø·Ø§ ÙƒÙŠ Ù†ÙƒÙˆÙ†ÙˆØ§ Ø¬Ø¯Ø¯ Ø§Ù„Ù„ÙŠ Ø­ÙƒÙŠÙ†Ø§ Ø¹Ù„ÙŠÙ‡Ù… Ù„Ø§ÙŠÙÙƒ Ù‡Ù†Ø§ Ø¨Ù„ÙˆØ³ Ø¨Ù„ÙˆØ³ ÙÙ„ÙŠÙƒØ³ÙŠØ¨Ù„ ÙƒÙŠ ØªØ®Ø¯Ù… Ù„Ù‡Ù… ÙÙŠ Ø§Ù„Ø§ÙØªØªØ§Ø­ Ø§Ù„Ø¨Ø§Ø±Ø­ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø¹Ø·ÙŠØª Ù„Ù‡Ù… Ø­ØµØ±ÙŠÙ‡ Ø±Ø§Ù†ÙŠ Ø¨Ø§Ø±ÙƒØª Ù„ÙƒØ§Ø±Ù…ÙˆÙ† Ù†ÙˆØ±Ù…Ø§Ù„Ù…ÙˆÙ† Ù…Ø§Ø·Ù„Ø¹ØªØ´ ÙÙŠ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ù‡Ø°Ø§ Ù†Ø¨Ø§Ø±ÙƒÙˆ Ø®ÙˆÙ†Ø§ Ø±ÙˆØ¬ÙŠ ÙˆØ³ÙŠ Ù†Ø²ÙŠÙ… Ù†Ø­ÙŠÙˆÙ‡ Ø¨Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ø¬Ø¯ÙŠØ¯Ù‡ Ø§Ø± Ø¬ÙŠ 360 Ø±Ø¨ÙŠ ÙŠÙˆÙÙ‚ Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ ÙˆÙŠÙƒÙˆÙ† Ù…Ø¬ØªÙ…Ø¹ Ø±Ù‚Ù…ÙŠ Ø¹Ù†Ø¯Ù‡ Ø§Ù…Ø¨Ø§ÙƒØª ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ù„Ù‡ Ù†Ø´ÙˆÙÙ‡Ù… ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ø¹Ù„Ù‰ Ø®Ù…Ø³ Ø³Ù†ÙˆØ§Øª ÙŠØ­Ø·ÙˆØ§ Ø­Ø§Ø¬Ù‡ ÙÙŠ Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ Ø­ØªÙ‰ Ù†Ø®Ø·Ø· Ø¹Ù„Ù‰ Ø®Ù…Ø³ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø¯ÙˆÙ†Ùƒ Ø§ ÙƒÙŠ Ù‚Ù„Ù†Ø§ Ø§Ù„ÙÙ„ÙŠÙƒØ³ÙŠØ¨Ù„ Ù„Ø§Ø¯ÙÙˆÙ†Ø·Ø¬ Ø¨Ù„ÙŠØ³ Ø±Ø§ ÙŠØ¯ÙˆÙ…ÙˆÙ†Ø¯ÙŠÙ†Ø§ Ù…Ø§ Ù†Ø®Ø¯Ù…ÙˆØ´ ØºÙŠØ± ÙƒÙˆÙ†ÙØ±Ø¬ÙŠØª ÙˆÙŠØ¨ Ø¨ØµØ­ Ø§Ø­Ù†Ø§ Ù„Ø§Ø²Ù…Ù†Ø§ Ù†Ø®Ø¯Ù…ÙˆØ§ ÙƒÙˆÙ†ÙØ±Ø¬ÙŠ ÙˆÙŠØ¨ Ø¯ÙˆÙ†Ùƒ Ø§Ù„Ù„Ø¹Ø¨Ù‡ Ø§Ù„Ù„ÙŠ Ø±Ø§ÙŠ ÙƒØ§ÙŠÙ†Ù‡ Ø¯Ø±Ùƒ ÙƒØ§ÙŠÙ†Ù‡ Ù„ÙŠ Ù…ÙŠØª Ù†Ù…ØªÙ‡Ø§ Ø§Ù†Ùƒ ØªÙƒØ±ÙŠ Ø­Ù…Ù„Ù‡ Ø§Ù„Ø§Ø¹Ù„Ø§Ù†ÙŠÙ‡ Ø§Ø¯ÙÙˆÙ†ØªØ§Ø¬'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# load chosen audio list\n",
    "chosen_audio_f = '../json/selected_audio_files.json'\n",
    "original_filtered = []\n",
    "\n",
    "with open(chosen_audio_f, 'r') as f:\n",
    "    chosen_audio_list = json.load(f)\n",
    "\n",
    "print(chosen_audio_list[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293caaf",
   "metadata": {},
   "source": [
    "We start with the Large-v3 cpu model. we use 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b59741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_dir = '../json'\n",
    "\n",
    "os.makedirs(saving_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2016c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”Š Transcribing: 013_chunk056.mp3\n",
      "â±  Took 106.71 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk152.mp3\n",
      "â±  Took 112.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk035.mp3\n",
      "â±  Took 105.54 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk053.mp3\n",
      "â±  Took 126.92 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk022.mp3\n",
      "â±  Took 155.55 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk141.mp3\n",
      "â±  Took 134.97 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk039.mp3\n",
      "â±  Took 121.89 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk020.mp3\n",
      "â±  Took 131.88 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk010.mp3\n",
      "â±  Took 119.32 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk107.mp3\n",
      "â±  Took 146.40 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk018.mp3\n",
      "â±  Took 173.38 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk015.mp3\n",
      "â±  Took 182.32 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk045.mp3\n",
      "â±  Took 109.45 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk058.mp3\n",
      "â±  Took 119.22 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk085.mp3\n",
      "â±  Took 342.53 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk013.mp3\n",
      "â±  Took 104.86 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk029.mp3\n",
      "â±  Took 125.01 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk021.mp3\n",
      "â±  Took 122.01 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk086.mp3\n",
      "â±  Took 106.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk041.mp3\n",
      "â±  Took 127.13 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk049.mp3\n",
      "â±  Took 113.08 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk005.mp3\n",
      "â±  Took 159.75 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk015.mp3\n",
      "â±  Took 130.06 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk043.mp3\n",
      "â±  Took 111.51 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk154.mp3\n",
      "â±  Took 153.36 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk083.mp3\n",
      "â±  Took 126.90 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk158.mp3\n",
      "â±  Took 153.66 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk056.mp3\n",
      "â±  Took 123.45 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk033.mp3\n",
      "â±  Took 109.38 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk122.mp3\n",
      "â±  Took 126.86 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk015.mp3\n",
      "â±  Took 170.33 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk050.mp3\n",
      "â±  Took 123.90 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk019.mp3\n",
      "â±  Took 124.35 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk134.mp3\n",
      "â±  Took 140.06 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 004_chunk005.mp3\n",
      "â±  Took 102.49 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk007.mp3\n",
      "â±  Took 120.14 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk009.mp3\n",
      "â±  Took 108.58 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk112.mp3\n",
      "â±  Took 106.48 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk003.mp3\n",
      "â±  Took 112.94 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk055.mp3\n",
      "â±  Took 107.43 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk037.mp3\n",
      "â±  Took 112.57 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk106.mp3\n",
      "â±  Took 111.52 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk063.mp3\n",
      "â±  Took 116.19 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk135.mp3\n",
      "â±  Took 106.65 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk103.mp3\n",
      "â±  Took 115.78 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 006_chunk001.mp3\n",
      "â±  Took 100.25 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk003.mp3\n",
      "â±  Took 153.42 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk056.mp3\n",
      "â±  Took 118.39 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk023.mp3\n",
      "â±  Took 89.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk035.mp3\n",
      "â±  Took 113.94 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk014.mp3\n",
      "â±  Took 132.26 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk006.mp3\n",
      "â±  Took 125.88 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk081.mp3\n",
      "â±  Took 116.46 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk050.mp3\n",
      "â±  Took 124.70 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk201.mp3\n",
      "â±  Took 121.81 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk155.mp3\n",
      "â±  Took 148.98 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk040.mp3\n",
      "â±  Took 121.71 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk035.mp3\n",
      "â±  Took 119.48 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk109.mp3\n",
      "â±  Took 157.96 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk067.mp3\n",
      "â±  Took 120.73 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk052.mp3\n",
      "â±  Took 125.72 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk088.mp3\n",
      "â±  Took 111.29 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk044.mp3\n",
      "â±  Took 131.74 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk129.mp3\n",
      "â±  Took 120.26 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk006.mp3\n",
      "â±  Took 123.67 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk101.mp3\n",
      "â±  Took 112.62 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk027.mp3\n",
      "â±  Took 111.56 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk001.mp3\n",
      "â±  Took 180.36 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk030.mp3\n",
      "â±  Took 160.00 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk058.mp3\n",
      "â±  Took 114.65 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk061.mp3\n",
      "â±  Took 107.36 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk103.mp3\n",
      "â±  Took 112.79 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk018.mp3\n",
      "â±  Took 108.60 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk104.mp3\n",
      "â±  Took 128.69 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk040.mp3\n",
      "â±  Took 132.82 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 005_chunk002.mp3\n",
      "â±  Took 65.72 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk021.mp3\n",
      "â±  Took 135.48 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk018.mp3\n",
      "â±  Took 135.67 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 007_chunk002.mp3\n",
      "â±  Took 79.89 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk070.mp3\n",
      "â±  Took 189.76 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk106.mp3\n",
      "â±  Took 121.32 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk123.mp3\n",
      "â±  Took 232.87 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk009.mp3\n",
      "â±  Took 113.27 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk059.mp3\n",
      "â±  Took 105.71 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk005.mp3\n",
      "â±  Took 108.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk004.mp3\n",
      "â±  Took 124.97 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk105.mp3\n",
      "â±  Took 189.33 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk042.mp3\n",
      "â±  Took 126.55 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk173.mp3\n",
      "â±  Took 235.67 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk041.mp3\n",
      "â±  Took 127.20 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk131.mp3\n",
      "â±  Took 103.53 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk025.mp3\n",
      "â±  Took 123.73 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk017.mp3\n",
      "â±  Took 143.74 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk015.mp3\n",
      "â±  Took 131.42 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk009.mp3\n",
      "â±  Took 191.37 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk002.mp3\n",
      "â±  Took 108.34 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk043.mp3\n",
      "â±  Took 107.39 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 012_chunk001.mp3\n",
      "â±  Took 123.21 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk047.mp3\n",
      "â±  Took 120.76 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk071.mp3\n",
      "â±  Took 104.56 seconds\n",
      "File saved successfully\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "Mean time: 129.59 s\n",
      "Min time : 65.72 s\n",
      "Max time : 342.53 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'test_whispercpp_large-v3.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../texts'\n",
    "model_name = \"large-v3\"\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in chosen_audio_list:\n",
    "    file_name = audio_f[\"audio\"] + \".mp3\"\n",
    "    audio_dir = \"../../metadata/chunks/audio\"\n",
    "    full_audio_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\nğŸ”Š Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"â±  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\nğŸ“Š Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74121428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”Š Transcribing: 013_chunk056.mp3\n",
      "â±  Took 71.43 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk152.mp3\n",
      "â±  Took 64.99 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk035.mp3\n",
      "â±  Took 63.42 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk053.mp3\n",
      "â±  Took 66.06 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk022.mp3\n",
      "â±  Took 75.20 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk141.mp3\n",
      "â±  Took 95.66 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk039.mp3\n",
      "â±  Took 66.12 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk020.mp3\n",
      "â±  Took 77.10 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk010.mp3\n",
      "â±  Took 64.49 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk107.mp3\n",
      "â±  Took 64.73 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk018.mp3\n",
      "â±  Took 67.98 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk015.mp3\n",
      "â±  Took 65.26 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk045.mp3\n",
      "â±  Took 64.88 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk058.mp3\n",
      "â±  Took 62.60 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk085.mp3\n",
      "â±  Took 90.31 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk013.mp3\n",
      "â±  Took 67.59 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk029.mp3\n",
      "â±  Took 66.56 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk021.mp3\n",
      "â±  Took 71.59 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk086.mp3\n",
      "â±  Took 62.34 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk041.mp3\n",
      "â±  Took 69.38 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk049.mp3\n",
      "â±  Took 67.91 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk005.mp3\n",
      "â±  Took 105.02 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk015.mp3\n",
      "â±  Took 68.27 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk043.mp3\n",
      "â±  Took 65.90 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk154.mp3\n",
      "â±  Took 71.77 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk083.mp3\n",
      "â±  Took 68.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk158.mp3\n",
      "â±  Took 68.10 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk056.mp3\n",
      "â±  Took 68.55 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk033.mp3\n",
      "â±  Took 95.90 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk122.mp3\n",
      "â±  Took 70.90 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk015.mp3\n",
      "â±  Took 115.98 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk050.mp3\n",
      "â±  Took 66.09 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk019.mp3\n",
      "â±  Took 77.01 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk134.mp3\n",
      "â±  Took 66.71 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 004_chunk005.mp3\n",
      "â±  Took 62.89 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002_chunk007.mp3\n",
      "â±  Took 103.88 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk009.mp3\n",
      "â±  Took 65.36 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk112.mp3\n",
      "â±  Took 86.25 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk003.mp3\n",
      "â±  Took 72.36 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk055.mp3\n",
      "â±  Took 64.01 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 020_chunk037.mp3\n",
      "â±  Took 65.75 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk106.mp3\n",
      "â±  Took 62.73 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk063.mp3\n",
      "â±  Took 72.19 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk135.mp3\n",
      "â±  Took 60.45 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk103.mp3\n",
      "â±  Took 64.68 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 006_chunk001.mp3\n",
      "â±  Took 74.01 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk003.mp3\n",
      "â±  Took 78.30 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk056.mp3\n",
      "â±  Took 81.92 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk023.mp3\n",
      "â±  Took 55.55 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk035.mp3\n",
      "â±  Took 62.47 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk014.mp3\n",
      "â±  Took 59.84 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk006.mp3\n",
      "â±  Took 66.76 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk081.mp3\n",
      "â±  Took 66.06 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk050.mp3\n",
      "â±  Took 91.23 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk201.mp3\n",
      "â±  Took 75.84 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk155.mp3\n",
      "â±  Took 94.95 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk040.mp3\n",
      "â±  Took 85.93 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk035.mp3\n",
      "â±  Took 64.12 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk109.mp3\n",
      "â±  Took 61.91 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk067.mp3\n",
      "â±  Took 66.54 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk052.mp3\n",
      "â±  Took 70.60 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk088.mp3\n",
      "â±  Took 62.37 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk044.mp3\n",
      "â±  Took 90.38 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk129.mp3\n",
      "â±  Took 65.81 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk006.mp3\n",
      "â±  Took 72.57 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk101.mp3\n",
      "â±  Took 67.11 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk027.mp3\n",
      "â±  Took 67.63 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk001.mp3\n",
      "â±  Took 80.22 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk030.mp3\n",
      "â±  Took 68.06 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk058.mp3\n",
      "â±  Took 64.29 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk061.mp3\n",
      "â±  Took 87.23 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk103.mp3\n",
      "â±  Took 74.61 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk018.mp3\n",
      "â±  Took 70.62 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk104.mp3\n",
      "â±  Took 84.09 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk040.mp3\n",
      "â±  Took 73.84 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 005_chunk002.mp3\n",
      "â±  Took 88.75 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk021.mp3\n",
      "â±  Took 80.73 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk018.mp3\n",
      "â±  Took 76.77 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 007_chunk002.mp3\n",
      "â±  Took 67.58 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk070.mp3\n",
      "â±  Took 102.05 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk106.mp3\n",
      "â±  Took 79.09 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk123.mp3\n",
      "â±  Took 85.78 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 022_chunk009.mp3\n",
      "â±  Took 64.19 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 016_chunk059.mp3\n",
      "â±  Took 83.95 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk005.mp3\n",
      "â±  Took 79.32 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk004.mp3\n",
      "â±  Took 79.61 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk105.mp3\n",
      "â±  Took 76.31 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk042.mp3\n",
      "â±  Took 75.18 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk173.mp3\n",
      "â±  Took 74.84 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk041.mp3\n",
      "â±  Took 72.87 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk131.mp3\n",
      "â±  Took 77.80 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk025.mp3\n",
      "â±  Took 106.30 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk017.mp3\n",
      "â±  Took 68.72 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 019_chunk015.mp3\n",
      "â±  Took 113.50 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 021_chunk009.mp3\n",
      "â±  Took 66.05 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 008_chunk002.mp3\n",
      "â±  Took 55.21 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 018_chunk043.mp3\n",
      "â±  Took 74.70 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 012_chunk001.mp3\n",
      "â±  Took 84.58 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 017_chunk047.mp3\n",
      "â±  Took 71.58 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 013_chunk071.mp3\n",
      "â±  Took 79.59 seconds\n",
      "File saved successfully\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "Mean time: 74.25 s\n",
      "Min time : 55.21 s\n",
      "Max time : 115.98 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'test_whispercpp_turbo.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../texts_turbo'\n",
    "model_name = \"turbo\"\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in chosen_audio_list:\n",
    "    file_name = audio_f[\"audio\"] + \".mp3\"\n",
    "    audio_dir = \"../../metadata/chunks/audio\"\n",
    "    full_audio_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\nğŸ”Š Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"â±  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\nğŸ“Š Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1de36",
   "metadata": {},
   "source": [
    "## Whispercpp Large-v3 stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad458b68",
   "metadata": {},
   "source": [
    "ğŸ“Š Summary:\n",
    "Mean time: 129.59 s\n",
    "Min time : 65.72 s\n",
    "Max time : 342.53 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39ae7",
   "metadata": {},
   "source": [
    "## Whispercpp Turbo stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b1a15",
   "metadata": {},
   "source": [
    "ğŸ“Š Summary:\n",
    "Mean time: 74.25 s\n",
    "Min time : 55.21 s\n",
    "Max time : 115.98 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffc6a4",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Turbo model is x1.75 faster </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d45e6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebeb293",
   "metadata": {},
   "source": [
    "The transcriptions are saved in **json/test_whisper_(model).json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57eaec",
   "metadata": {},
   "source": [
    "## Manual Evaluation\n",
    "We evaluate the quality of transcriptions manually\n",
    "- 013_chunk056: Turbo clearly better\n",
    "- 017_chunk152: Large is mixing sentnce order, Turbo is good\n",
    "- 013_chunk035: Kinda the same quality, both good\n",
    "- 008_chunk022: Both are bad and misses a portion of speech\n",
    "- 020_chunk039: Turbo is good, Large is same\n",
    "- 016_chunk010: Turbo is good but mixes sentences, Large is good\n",
    "- 022_chunk015: both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f844b3",
   "metadata": {},
   "source": [
    "## Numerical Evaluation(cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6e92b",
   "metadata": {},
   "source": [
    "we load the both transcription data, with youtube(original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be968179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whispercpp_turbo.json'\n",
    "whisper_large_t = '../json/test_whispercpp_large-v3.json'\n",
    "# original_t = '../json/text_audio_mapping.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n",
    "\n",
    "# with open(original_t, 'r') as f:\n",
    "#     original_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c07c97",
   "metadata": {},
   "source": [
    "### Generate embeddings for whisper transcriptions and save them in new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55411129",
   "metadata": {},
   "source": [
    "Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f4a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "your_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911b212",
   "metadata": {},
   "source": [
    "Generating embedding using OpenAI multilingual transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# we use 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def add_embeddings(data_list, text_key):\n",
    "    \"\"\"\n",
    "    Generates and adds embeddings for each item in a list of dictionaries.\n",
    "\n",
    "    Args: \n",
    "        data_list (list): A list of dictionaries, where each dict has a text field.\n",
    "        text_key (str): The key for the text field in each dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list with an '_embedding' key added to each dictionary.\n",
    "    \"\"\"\n",
    "    texts = [item.get(text_key) for item in data_list]\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "\n",
    "    for i, item in enumerate(data_list):\n",
    "        new_key = text_key + '_embedding'\n",
    "        item[new_key] = embeddings[i].tolist() # Convert numpy array to list for JSON serialization\n",
    "\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317cdd34",
   "metadata": {},
   "source": [
    "save in a different file for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11855735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turbo_embeddings_path = '../json/turbo_cpp_embeddings.json'\n",
    "large_embeddings_path = '../json/large_cpp_embeddings.json'\n",
    "\n",
    "origial_embeddings_path = '../json/origial_embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33093e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_embeddings = add_embeddings(turbo_transcriptions, \"transcription\")\n",
    "large_embeddings = add_embeddings(large_transcriptions, \"transcription\")\n",
    "\n",
    "\n",
    "with open(turbo_embeddings_path, 'w') as f:\n",
    "    json.dump(turbo_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(large_embeddings_path, 'w') as f:\n",
    "    json.dump(large_embeddings, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619c1b1",
   "metadata": {},
   "source": [
    "## Apply cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b6afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(turbo_embeddings_path, 'r') as f:\n",
    "    turbo_embeddings = json.load(f)\n",
    "\n",
    "with open(large_embeddings_path, 'r') as f:\n",
    "    large_embeddings = json.load(f)\n",
    "\n",
    "with open(origial_embeddings_path, 'r') as f:\n",
    "    original_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8472b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_file = '../json/turbo_cpp_vs_large.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7565e",
   "metadata": {},
   "source": [
    "Apply cosine similarity and save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad2f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for row in original_embeddings:\n",
    "    original_emb = row['text_embedding']\n",
    "    turbo_emb = next((f['transcription_embedding'] for f in turbo_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "    large_emb = next((f['transcription_embedding'] for f in large_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "\n",
    "    if not turbo_emb:\n",
    "        print(f\"NOT FOUND turbo embedding for file {row['audio']}\")\n",
    "\n",
    "    if not large_emb:\n",
    "        print(f\"NOT FOUND large embedding for file {row['audio']}\")\n",
    "    original_emb = np.array(original_emb).reshape(1, -1)\n",
    "    turbo_emb = np.array(turbo_emb).reshape(1, -1)\n",
    "    large_emb = np.array(large_emb).reshape(1, -1)\n",
    "\n",
    "    turbo_cosine = cosine_similarity(original_emb, turbo_emb)[0][0]\n",
    "    large_cosine = cosine_similarity(original_emb, large_emb)[0][0]\n",
    "\n",
    "    metric_list.append({\n",
    "        \"audio\": row['audio'],\n",
    "        'turbo_cosine': turbo_cosine,\n",
    "        'large_cosine': large_cosine\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metric_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17240307",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afa3ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>turbo_cosine</th>\n",
       "      <th>large_cosine</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_chunk007</td>\n",
       "      <td>0.924972</td>\n",
       "      <td>0.874039</td>\n",
       "      <td>-0.050933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_chunk018</td>\n",
       "      <td>0.939545</td>\n",
       "      <td>0.949126</td>\n",
       "      <td>0.009581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_chunk019</td>\n",
       "      <td>0.956090</td>\n",
       "      <td>0.927396</td>\n",
       "      <td>-0.028694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_chunk005</td>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.021302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_chunk002</td>\n",
       "      <td>0.712337</td>\n",
       "      <td>0.313424</td>\n",
       "      <td>-0.398913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>022_chunk009</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>0.873117</td>\n",
       "      <td>-0.112661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>022_chunk015</td>\n",
       "      <td>0.971704</td>\n",
       "      <td>0.979342</td>\n",
       "      <td>0.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>022_chunk027</td>\n",
       "      <td>0.967482</td>\n",
       "      <td>0.826178</td>\n",
       "      <td>-0.141304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>022_chunk035</td>\n",
       "      <td>0.908721</td>\n",
       "      <td>0.945594</td>\n",
       "      <td>0.036873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>022_chunk055</td>\n",
       "      <td>0.883070</td>\n",
       "      <td>0.901589</td>\n",
       "      <td>0.018518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio  turbo_cosine  large_cosine  difference\n",
       "0   002_chunk007      0.924972      0.874039   -0.050933\n",
       "1   002_chunk018      0.939545      0.949126    0.009581\n",
       "2   002_chunk019      0.956090      0.927396   -0.028694\n",
       "3   004_chunk005      0.942761      0.964063    0.021302\n",
       "4   005_chunk002      0.712337      0.313424   -0.398913\n",
       "..           ...           ...           ...         ...\n",
       "95  022_chunk009      0.985778      0.873117   -0.112661\n",
       "96  022_chunk015      0.971704      0.979342    0.007638\n",
       "97  022_chunk027      0.967482      0.826178   -0.141304\n",
       "98  022_chunk035      0.908721      0.945594    0.036873\n",
       "99  022_chunk055      0.883070      0.901589    0.018518\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Comparison for CPU ---\n",
      "turbo_mean: 0.916271\n",
      "large_mean: 0.916341\n",
      "turbo_std: 0.096982\n",
      "large_std: 0.092034\n",
      "avg_difference: 0.000070\n",
      "turbo_better_count: 52.000000\n",
      "large_better_count: 48.000000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metric_list = json.load(f)\n",
    "\n",
    "# put into DataFrame\n",
    "df = pd.DataFrame(metric_list)\n",
    "\n",
    "# compute difference\n",
    "df[\"difference\"] = df[\"large_cosine\"] - df[\"turbo_cosine\"]\n",
    "\n",
    "# summary statistics\n",
    "summary = {\n",
    "    \"turbo_mean\": df[\"turbo_cosine\"].mean(),\n",
    "    \"large_mean\": df[\"large_cosine\"].mean(),\n",
    "    \"turbo_std\": df[\"turbo_cosine\"].std(),\n",
    "    \"large_std\": df[\"large_cosine\"].std(),\n",
    "    \"avg_difference\": df[\"difference\"].mean(),\n",
    "    \"turbo_better_count\": (df[\"difference\"] < 0).sum(),\n",
    "    \"large_better_count\": (df[\"difference\"] > 0).sum()\n",
    "}\n",
    "\n",
    "display(df)\n",
    "print(\"\\n--- Summary Comparison for CPU ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ea505",
   "metadata": {},
   "source": [
    "# Whisper Large on low quality audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c857879",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b3b93",
   "metadata": {},
   "source": [
    "## CPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6051b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LOW_AUDIO_FOLDER = r\"C:\\Users\\ACER\\Desktop\\ASR\\code-low\\raw_audio\"\n",
    "low_audio_files =[f for f in os.listdir(LOW_AUDIO_FOLDER) if f.endswith(\".mp3\") and f.startswith(\"0\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cf2efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”Š Transcribing: 001.mp3\n",
      "â±  Took 590.45 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 002.mp3\n",
      "â±  Took 1583.96 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 003.mp3\n",
      "â±  Took 912.35 seconds\n",
      "\n",
      "ğŸ”Š Transcribing: 004.mp3\n",
      "â±  Took 347.04 seconds\n",
      "File saved successfully\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "Mean time: 858.45 s\n",
      "Min time : 347.04 s\n",
      "Max time : 1583.96 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "cpu_test_file = 'low_quality_test_whispercpp_large-v3.json'\n",
    "\n",
    "NUM_THREADS = 8\n",
    "text_files_dir = '../low_texts'\n",
    "model_name = \"large-v3\"\n",
    "saving_dir = '../json'\n",
    "\n",
    "transcriptions_list = []\n",
    "timings = [] \n",
    "\n",
    "for audio_f in low_audio_files:\n",
    "    file_name = audio_f\n",
    "    full_audio_path = os.path.join(LOW_AUDIO_FOLDER, file_name)\n",
    "\n",
    "\n",
    "    print(f\"\\nğŸ”Š Transcribing: {file_name}\")\n",
    "    start = time.perf_counter()\n",
    "    transcript = transcribe_audio(\n",
    "        audio_path=full_audio_path,\n",
    "        exe_path=r\"C:\\Users\\ACER\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe\",\n",
    "        language=\"ar\",\n",
    "        threads=NUM_THREADS,\n",
    "        text_output_dir=text_files_dir,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    transcript = transcript.replace(\"\\n\", \"\")\n",
    "\n",
    "    duration = end - start\n",
    "    timings.append(duration)\n",
    "    print(f\"â±  Took {duration:.2f} seconds\")\n",
    "\n",
    "    transcriptions_list.append({\n",
    "        \"transcription\": transcript,\n",
    "        \"audio\": file_name,\n",
    "        \"duration_seconds\": round(duration, 2)\n",
    "    })\n",
    "\n",
    "# Save transcriptions with timing\n",
    "output_transcriptions = os.path.join(saving_dir, cpu_test_file)\n",
    "with open(output_transcriptions, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transcriptions_list, f, ensure_ascii=False, indent=4)\n",
    "    print(\"File saved successfully\")\n",
    "\n",
    "# ---- Summary statistics ----\n",
    "if timings:\n",
    "    mean_time = statistics.mean(timings)\n",
    "    min_time = min(timings)\n",
    "    max_time = max(timings)\n",
    "    print(\"\\nğŸ“Š Summary:\")\n",
    "    print(f\"Mean time: {mean_time:.2f} s\")\n",
    "    print(f\"Min time : {min_time:.2f} s\")\n",
    "    print(f\"Max time : {max_time:.2f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid audio files were processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38226b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_key = os.getenv(\"GEMINI_KEY\")\n",
    "\n",
    "# Configure gemini API key\n",
    "genai.configure(api_key=gemini_key)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash',generation_config={\n",
    "    \"temperature\": 0.2,\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1697fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "classes = [\"comedy\", \"business\", \"cars\", \"tourism\", \"stories\"]\n",
    "\n",
    "\n",
    "def classify_text(text, language = \"algerian\"):\n",
    "    \n",
    "    prompt = (\n",
    "        f\"The following {language} text may include more than one speaker. \"\n",
    "        f\"Understand the general topics, and based on that classify this text into: {classes}. \"\n",
    "        f\"Allow multiple classes and return only a Python list \"\n",
    "        f\"(response must start with [ and end with ]). \\nText:\\n{text}\"\n",
    "    )\n",
    "    try:\n",
    "        raw = model.generate_content(prompt).text\n",
    "        result_classes = ast.literal_eval(raw)\n",
    "        \n",
    "        return result_classes\n",
    "    except Exception:\n",
    "        print(\"Error during text classification\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368875e5",
   "metadata": {},
   "source": [
    "### Classify the Turbo and Large-v3 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70afa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whispercpp_turbo.json'\n",
    "whisper_large_t = '../json/test_whispercpp_large-v3.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414cd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_refinement_prompt = \"\"\" You are an expert in Algerian Arabic (Darja).  \n",
    "Your task is to proofread the following text.  \n",
    "\n",
    "- understand and keep the original context, \n",
    "- Correct spelling mistakes.  \n",
    "- Fix spacing (remove extra spaces, add missing spaces).  \n",
    "- Do NOT change the sentence structure or meaning, \n",
    "  and do not add extra words that are not in the sentence. \n",
    "- Keep the natural Darja style and tone and emotions\n",
    "\n",
    "Return only the corrected text. here's the text: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "169375af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comedy', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'cars']\n",
      "['comedy']\n",
      "['tourism', 'stories']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['cars', 'business']\n",
      "['business', 'stories']\n",
      "['comedy', 'stories', 'business']\n",
      "['business', 'stories']\n",
      "['stories', 'business', 'comedy']\n",
      "['stories', 'comedy']\n",
      "['stories']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['stories']\n",
      "['comedy', 'business']\n",
      "['comedy', 'stories']\n",
      "['business', 'cars', 'stories']\n",
      "['comedy', 'business']\n",
      "['business']\n",
      "['stories', 'comedy']\n"
     ]
    }
   ],
   "source": [
    "for row in turbo_transcriptions[:30]:\n",
    "    try:\n",
    "        text = row['transcription']\n",
    "        full_prompt = base_refinement_prompt + text\n",
    "        refined = model.generate_content(full_prompt).text\n",
    "        result = classify_text(refined)\n",
    "\n",
    "        row['refined'] = refined\n",
    "        row['classes'] = result\n",
    "\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "with open(whisper_turbo_t, 'w') as f:\n",
    "    json.dump(turbo_transcriptions, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65caa17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comedy', 'stories']\n",
      "['business', 'stories']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'cars']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['tourism']\n",
      "['business', 'tourism']\n",
      "['stories']\n",
      "['comedy', 'business']\n",
      "['stories', 'business']\n",
      "['stories']\n",
      "['stories']\n",
      "['business', 'stories']\n",
      "['stories', 'comedy']\n",
      "['business']\n",
      "['business', 'stories']\n",
      "['business', 'stories']\n",
      "['stories']\n",
      "['business', 'comedy']\n",
      "['comedy', 'stories']\n",
      "['comedy', 'business']\n",
      "['business', 'stories']\n",
      "['business']\n",
      "['comedy', 'stories']\n"
     ]
    }
   ],
   "source": [
    "for row in large_transcriptions[:30]:\n",
    "    try:\n",
    "        text = row['transcription']\n",
    "        full_prompt = base_refinement_prompt + text\n",
    "        refined = model.generate_content(full_prompt).text\n",
    "        result = classify_text(refined)\n",
    "\n",
    "        row['refined'] = refined\n",
    "        row['classes'] = result\n",
    "\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "with open(whisper_large_t, 'w') as f:\n",
    "    json.dump(large_transcriptions, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d5279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
