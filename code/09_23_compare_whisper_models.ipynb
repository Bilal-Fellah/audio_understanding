{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1774a07d",
   "metadata": {},
   "source": [
    "# Benchmark and compare Whisper models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53315d",
   "metadata": {},
   "source": [
    "In this notebook, we try to apply transcription and classification with \n",
    "\n",
    "Whisper (Large vs Turbo, CPP AND GPU versions) and Analyse the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b50ca",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74716fe",
   "metadata": {},
   "source": [
    "We start with generating transcription with both models(turbo and large-v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf586a2",
   "metadata": {},
   "source": [
    "Let's choose a sample of random audios(100 units), so we make sure our sample is representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a938d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# audio_folder = '../../metadata/chunks/audio' \n",
    "# transcriptions_file = '../../metadata/chunks/text_audio_mapping.json'\n",
    "# saving_file = '../json/selected_audio_files.json'\n",
    "# AUDIO_NUM = 100\n",
    "\n",
    "# audio_files = os.listdir(audio_folder)\n",
    "# random.shuffle(audio_files)\n",
    "\n",
    "# selected_audio_files = audio_files[:AUDIO_NUM]\n",
    "\n",
    "# # add original transcriptions\n",
    "# data = None\n",
    "# with open(transcriptions_file, 'r') as f:\n",
    "#     transcriptions = json.load(f)\n",
    "\n",
    "# json_objects = []\n",
    "\n",
    "# for file in selected_audio_files:\n",
    "#     audio_name = file.replace(\".mp3\", \"\")\n",
    "#     transcription = next(t['text'] for t in transcriptions if t['audio'] == audio_name )\n",
    "#     json_objects.append(\n",
    "#         {\n",
    "#             \"audio\": audio_name,\n",
    "#             \"transcription\": transcription\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# with open(saving_file, 'w') as f:\n",
    "#     json.dump(json_objects, f, ensure_ascii=False)\n",
    "\n",
    "# print(selected_audio_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c0f2",
   "metadata": {},
   "source": [
    "We will transcribe these audio files using Whisper Large-v3 and Turbo and see the quality and time\n",
    "\n",
    "This will run in colab Tesla T4 (12.7 GB VRAM as the runtime shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86096e5b",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae61c18",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats (first run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec241",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ“Š Summary:\n",
    "\n",
    "Mean time: 27.55 s\n",
    "Min time : 7.81 s\n",
    "Max time : 101.91 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058386f5",
   "metadata": {},
   "source": [
    "## Whisper Large-v3 stats(second run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddce50",
   "metadata": {},
   "source": [
    "ðŸ“Š Summary:\n",
    "Mean time: 26.32 s\n",
    "Min time : 9.90 s\n",
    "Max time : 64.60 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d388c5",
   "metadata": {},
   "source": [
    "## Whisper Turbo stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e8132",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ“Š Summary:\n",
    "Mean time: 8.86 s\n",
    "Min time : 3.21 s\n",
    "Max time : 21.19 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5e82f",
   "metadata": {},
   "source": [
    "### <span style='color:blue'> *Turbo is more thatn x3 times faster than Large* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94e50e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01f578",
   "metadata": {},
   "source": [
    "The transcriptions are saved in **json/test_whisper_(model).json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac2951",
   "metadata": {},
   "source": [
    "## Manual Evaluation\n",
    "We evaluate the quality of transcriptions manually\n",
    "- 013_chunk056: Turbo much better\n",
    "- 017_chunk152: Large is horrible, Turbo is good\n",
    "- 013_chunk035: Kinda the same quality, both good\n",
    "- 008_chunk022: Large misses a portion of speech, Turbo is worse\n",
    "- 020_chunk039: Turbo is good, Large is same\n",
    "- 016_chunk010: Large is better\n",
    "- 022_chunk015: both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceec0b9",
   "metadata": {},
   "source": [
    "## Numerical Evaluation(cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aecb1f",
   "metadata": {},
   "source": [
    "we load the both transcription data, with youtube(original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a1a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "whisper_turbo_t = '../json/test_whisper_turbo.json'\n",
    "whisper_large_t = '../json/test_whisper_large-v3.json'\n",
    "original_t = '../json/text_audio_mapping.json'\n",
    "\n",
    "with open(whisper_turbo_t, 'r') as f:\n",
    "    turbo_transcriptions = json.load(f)\n",
    "\n",
    "with open(whisper_large_t, 'r') as f:\n",
    "    large_transcriptions = json.load(f)\n",
    "\n",
    "with open(original_t, 'r') as f:\n",
    "    original_transcriptions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068788e",
   "metadata": {},
   "source": [
    "Filter originals list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43aebb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick test: length of filtered list: 100\n"
     ]
    }
   ],
   "source": [
    "# load chosen audio list\n",
    "chosen_audio_f = '../json/selected_audio_files.json'\n",
    "original_filtered = []\n",
    "\n",
    "with open(chosen_audio_f, 'r') as f:\n",
    "    chosen_audio_list = json.load(f)\n",
    "for row in original_transcriptions:\n",
    "    found = next((1 for f in chosen_audio_list if f['audio'] == row['audio']), None)\n",
    "    if found:\n",
    "        original_filtered.append(row)\n",
    "\n",
    "print(f\"quick test: length of filtered list: {len(original_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb72cdf",
   "metadata": {},
   "source": [
    "### Generate embeddings for whisper transcriptions and save them in new files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b29c5",
   "metadata": {},
   "source": [
    "Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b360f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "your_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8493ee5",
   "metadata": {},
   "source": [
    "Generating embedding using OpenAI multilingual transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff3f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# we use 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def add_embeddings(data_list, text_key):\n",
    "    \"\"\"\n",
    "    Generates and adds embeddings for each item in a list of dictionaries.\n",
    "\n",
    "    Args: \n",
    "        data_list (list): A list of dictionaries, where each dict has a text field.\n",
    "        text_key (str): The key for the text field in each dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list with an '_embedding' key added to each dictionary.\n",
    "    \"\"\"\n",
    "    texts = [item.get(text_key) for item in data_list]\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "\n",
    "    for i, item in enumerate(data_list):\n",
    "        new_key = text_key + '_embedding'\n",
    "        item[new_key] = embeddings[i].tolist() # Convert numpy array to list for JSON serialization\n",
    "\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d1e97",
   "metadata": {},
   "source": [
    "save in a different file for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa74dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turbo_embeddings_path = '../json/turbo_embeddings.json'\n",
    "large_embeddings_path = '../json/large_embeddings.json'\n",
    "origial_embeddings_path = '../json/origial_embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_embeddings = add_embeddings(turbo_transcriptions, \"transcription\")\n",
    "large_embeddings = add_embeddings(large_transcriptions, \"transcription\")\n",
    "original_embeddings = add_embeddings(original_filtered, \"text\")\n",
    "\n",
    "\n",
    "with open(turbo_embeddings_path, 'w') as f:\n",
    "    json.dump(turbo_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(large_embeddings_path, 'w') as f:\n",
    "    json.dump(large_embeddings, f, ensure_ascii=False)\n",
    "\n",
    "with open(origial_embeddings_path, 'w') as f:\n",
    "    json.dump(original_embeddings, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c44639",
   "metadata": {},
   "source": [
    "## Apply cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9356a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(turbo_embeddings_path, 'r') as f:\n",
    "    turbo_embeddings = json.load(f)\n",
    "\n",
    "with open(large_embeddings_path, 'r') as f:\n",
    "    large_embeddings = json.load(f)\n",
    "\n",
    "with open(origial_embeddings_path, 'r') as f:\n",
    "    original_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196033d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_file = '../json/turbo_vs_large.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51a5dd",
   "metadata": {},
   "source": [
    "Apply cosine similarity and save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0767f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for row in original_embeddings:\n",
    "    original_emb = row['text_embedding']\n",
    "    turbo_emb = next((f['transcription_embedding'] for f in turbo_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "    large_emb = next((f['transcription_embedding'] for f in large_embeddings if f['audio'].replace(\".mp3\", \"\") == row['audio']), None)\n",
    "\n",
    "    if not turbo_emb:\n",
    "        print(f\"NOT FOUND turbo embedding for file {row['audio']}\")\n",
    "\n",
    "    if not large_emb:\n",
    "        print(f\"NOT FOUND large embedding for file {row['audio']}\")\n",
    "    original_emb = np.array(original_emb).reshape(1, -1)\n",
    "    turbo_emb = np.array(turbo_emb).reshape(1, -1)\n",
    "    large_emb = np.array(large_emb).reshape(1, -1)\n",
    "\n",
    "    turbo_cosine = cosine_similarity(original_emb, turbo_emb)[0][0]\n",
    "    large_cosine = cosine_similarity(original_emb, large_emb)[0][0]\n",
    "\n",
    "    metric_list.append({\n",
    "        \"audio\": row['audio'],\n",
    "        'turbo_cosine': turbo_cosine,\n",
    "        'large_cosine': large_cosine\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metric_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6b40c",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bdcd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>turbo_cosine</th>\n",
       "      <th>large_cosine</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_chunk007</td>\n",
       "      <td>0.957282</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>-0.028034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_chunk018</td>\n",
       "      <td>0.953961</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>-0.020346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_chunk019</td>\n",
       "      <td>0.894270</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.049578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_chunk005</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.940228</td>\n",
       "      <td>0.036657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_chunk002</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.950694</td>\n",
       "      <td>-0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>022_chunk009</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.833761</td>\n",
       "      <td>-0.154815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>022_chunk015</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.876124</td>\n",
       "      <td>-0.089463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>022_chunk027</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>0.012392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>022_chunk035</td>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.886476</td>\n",
       "      <td>-0.020563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>022_chunk055</td>\n",
       "      <td>0.842067</td>\n",
       "      <td>0.937556</td>\n",
       "      <td>0.095489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio  turbo_cosine  large_cosine  difference\n",
       "0   002_chunk007      0.957282      0.929248   -0.028034\n",
       "1   002_chunk018      0.953961      0.933615   -0.020346\n",
       "2   002_chunk019      0.894270      0.943848    0.049578\n",
       "3   004_chunk005      0.903571      0.940228    0.036657\n",
       "4   005_chunk002      0.972451      0.950694   -0.021757\n",
       "..           ...           ...           ...         ...\n",
       "95  022_chunk009      0.988576      0.833761   -0.154815\n",
       "96  022_chunk015      0.965587      0.876124   -0.089463\n",
       "97  022_chunk027      0.908584      0.920975    0.012392\n",
       "98  022_chunk035      0.907040      0.886476   -0.020563\n",
       "99  022_chunk055      0.842067      0.937556    0.095489\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Comparison ---\n",
      "turbo_mean: 0.9261\n",
      "large_mean: 0.9148\n",
      "turbo_std: 0.0809\n",
      "large_std: 0.0644\n",
      "avg_difference: -0.0113\n",
      "turbo_better_count: 66.0000\n",
      "large_better_count: 34.0000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metric_list = json.load(f)\n",
    "\n",
    "# put into DataFrame\n",
    "df = pd.DataFrame(metric_list)\n",
    "\n",
    "# compute difference\n",
    "df[\"difference\"] = df[\"large_cosine\"] - df[\"turbo_cosine\"]\n",
    "\n",
    "# summary statistics\n",
    "summary = {\n",
    "    \"turbo_mean\": df[\"turbo_cosine\"].mean(),\n",
    "    \"large_mean\": df[\"large_cosine\"].mean(),\n",
    "    \"turbo_std\": df[\"turbo_cosine\"].std(),\n",
    "    \"large_std\": df[\"large_cosine\"].std(),\n",
    "    \"avg_difference\": df[\"difference\"].mean(),\n",
    "    \"turbo_better_count\": (df[\"difference\"] < 0).sum(),\n",
    "    \"large_better_count\": (df[\"difference\"] > 0).sum()\n",
    "}\n",
    "\n",
    "display(df)\n",
    "print(\"\\n--- Summary Comparison ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3c653",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d39a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
